@inproceedings{ownShortPaper,
  author = {Stucki, Simon and Ackermann, Philipp},
  title = {Physically-based Path Tracer using WebGPU and OpenPBR},
  year = {2024},
  isbn = {9798400706899},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3665318.3677158},
  doi = {10.1145/3665318.3677158},
  abstract = {This work presents a web-based, open-source path tracer for rendering physically-based 3D scenes using WebGPU and the OpenPBR surface shading model. While rasterization has been the dominant real-time rendering technique on the web since WebGL’s introduction in 2011, it struggles with global illumination. This necessitates more complex techniques, often relying on pregenerated artifacts to attain the desired level of visual fidelity. Path tracing inherently addresses these limitations but at the cost of increased rendering time. Our work focuses on industrial applications where highly customizable products are common and real-time performance is not critical. We leverage WebGPU to implement path tracing on the web, integrating the OpenPBR standard for physically-based material representation. The result is a near real-time path tracer capable of rendering high-fidelity 3D scenes directly in web browsers, eliminating the need for pregenerated assets. Our implementation demonstrates the potential of WebGPU for advanced rendering techniques and opens new possibilities for web-based 3D visualization in industrial applications.},
  booktitle = {Proceedings of the 29th International ACM Conference on 3D Web Technology},
  articleno = {4},
  numpages = {6},
  keywords = {OpenPBR, WebGPU, physically-based rendering, web path tracer},
  location = {Guimar\~{a}es, Portugal},
  series = {WEB3D '24}
}

@online{webgpuSpecification,
  title = {WebGPU},
  author = {{W3C group for GPU web standards}},
  month = {August},
  year = {2024},
  url = {https://www.w3.org/TR/webgpu/},
  lastaccessed = "Aug 11, 2024",
}

@online{wgslSpecification,
  title = {WebGPU Shading Language},
  author = {{W3C group for GPU web standards}},
  month = {July},
  year = {2024},
  url = {https://www.w3.org/TR/WGSL},
  lastaccessed = "Aug 11, 2024",
}

@online{webGlComputeDraft,
  title = "WebGL 2.0 Compute",
  author = {He, Yunchao and Qin, Jiajia and Russell, Ken and Shao, Jiawei  and Jiang, Yizhou  and Cao, Xinghua and Chen, Jie and Hu, Jiajie},
  month = {March},
  year = {2021},
  url = {https://registry.khronos.org/webgl/specs/latest/2.0-compute/},
  lastaccessed = "Aug 30, 2024",
}

@online{gltfSpecification,
  title = {glTF 2.0 Specification},
  author = {{Khronos Group}},
  month = {October},
  year = {2021},
  url = {https://registry.khronos.org/glTF/specs/2.0/glTF-2.0.html},
  lastaccessed = "Aug 11, 2024",
}

@article{flynnTaxonomy,
  author={Flynn, Michael J.},
  journal={Proceedings of the IEEE}, 
  title={Very high-speed computing systems}, 
  year={1966},
  volume={54},
  number={12},
  pages={1901-1909},
  keywords={Computer aided instruction;Large-scale systems;Impedance matching;Art;Scientific computing;Arithmetic;Pervasive computing;Hardware;Turing machines},
  doi={10.1109/PROC.1966.5273}
}

@ARTICLE{flynnTaxonomy2,
  author={Flynn, Michael J.},
  journal={IEEE Transactions on Computers}, 
  title={Some Computer Organizations and Their Effectiveness}, 
  year={1972},
  volume={C-21},
  number={9},
  pages={948-960},
  keywords={Organizations;Computers;Entropy;Computational modeling;Data mining;Probability density function;Bandwidth;Computer organization;instruction stream;overlapped;parallel processors;resource hierarchy},
  doi={10.1109/TC.1972.5009071}}

@ARTICLE{evolutionOfGPU,
  author={Dally, William J. and Keckler, Stephen W. and Kirk, David B.},
  journal={IEEE Micro}, 
  title={Evolution of the Graphics Processing Unit (GPU)}, 
  year={2021},
  volume={41},
  number={6},
  pages={42-51},
  keywords={Graphics processing units},
  doi={10.1109/MM.2021.3113475}
}

@phdthesis{surfaceAlgorithmProcessor,
  author = {Watkins, Gary Scott},
  title = {A real time visible surface algorithm},
  year = {1970},
  publisher = {The University of Utah},
  note = {AAI7023061}
}

@article{chapSIMDgpu,
  author = {Levinthal, Adam and Porter, Thomas},
  title = {Chap - a SIMD graphics processor},
  year = {1984},
  issue_date = {July 1984},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {18},
  number = {3},
  issn = {0097-8930},
  url = {https://doi.org/10.1145/964965.808581},
  doi = {10.1145/964965.808581},
  abstract = {Special purpose processing systems designed for specific applications can provide extremely high performance at moderate cost. One such processor is presented for executing graphics and image processing algorithms as the basis of a digital film printer. Pixels in the system contain four parallel components: RGB for full color and an alpha channel for retaining transparency information. The data path of the processor contains four arithmetic elements connected through a crossbar network to a tessellated scratchpad memory. The single instruction, multiple data stream (SIMD) processor executes instructions on four pixel components in parallel. The instruction control unit (ICU) maintains an activity stack for tracking block-structured code, using data-dependent activity flags for conditional disabling subsets of the ALUs. Nested loops and if-then-else constructs can be programmed directly, with the ICU disabling and reenabling ALUs on the basis of their individual status bits.},
  journal = {SIGGRAPH Comput. Graph.},
  month = {jan},
  pages = {77–82},
  numpages = {6},
  keywords = {Tesselation, SIMD architecture, Parallel processing, Digital film printers, Computer graphics, Compositing}
}

@ARTICLE{sigWorkstation,
  author={Akeley, K.},
  journal={IEEE Computer Graphics and Applications}, 
  title={The Silicon Graphics 4D/240GTX superworkstation}, 
  year={1989},
  volume={9},
  number={4},
  pages={71-83},
  keywords={Silicon;Computer graphics;Displays;Monitoring;Workstations;Computer architecture;Hardware;Pixel;Supercomputers;Central Processing Unit},
  doi={10.1109/38.31466}
}

@inproceedings{appel1968shading,
    author = {Appel, Arthur},
    title = {Some techniques for shading machine renderings of solids},
    year = {1968},
    isbn = {9781450378970},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1468075.1468082},
    doi = {10.1145/1468075.1468082},
    abstract = {Some applications of computer graphics require a vivid illusion of reality. These include the spatial organization of machine parts, conceptual architectural design, simulation of mechanisms, and industrial design. There has been moderate success in the automatic generation of wire frame, cardboard model, polyhedra, and quadric surface line drawings. The capability of the machine to generate vivid sterographic pictures has been demonstrated. There are, however considerable reasons for developing techniques by which line drawings of solids can be shaded, especially the enhancement of the sense of solidity and depth. Figures 1 and 2 illustrate the value of shading and shadow casting in spatial description. In the line drawing there is no clue as to the relative position of the flat plane and the sheet metal console. When shadows are rendered, it is clear that the plane is below and to the rear of the console, and the hollow nature of the sheet metal assembly is emphasized. Shading can specify the tone or color of a surface and the amount of light falling upon that surface from one or more light sources. Shadows when sharply defined tend to suggest another viewpoint and improves surface definition. When controlled, shading can also emphasize particular parts of the drawing. If techniques for the automatic determination of chiaroscuro with good resolution should prove to be competitive with line drawings, and this is a possibility, machine generated photographs might replace line drawings as the principal mode of graphical communication in engineering and architecture.},
    booktitle = {Proceedings of the April 30--May 2, 1968, Spring Joint Computer Conference},
    pages = {37–45},
    numpages = {9},
    location = {Atlantic City, New Jersey},
    series = {AFIPS '68 (Spring)}
}

@book{fowles1989introduction,
  title={Introduction to modern optics},
  author={Fowles, Grant R},
  year={1989},
  publisher={Courier Corporation}
}

@article{bmrt,
    author = {Larry Gritz and James K. Hahn},
    title = {BMRT: A Global Illumination Implementation of the RenderMan Standard},
    journal = {Journal of Graphics Tools},
    volume = {1},
    number = {3},
    pages = {29--47},
    year = {1996},
    publisher = {Taylor \& Francis},
    doi = {10.1080/10867651.1996.10487462},
    URL = {https://doi.org/10.1080/10867651.1996.10487462},
}

@Manual{POV_Ray_Documentation,
  title = {POV-Ray: Documentation},
  author = {{POV-Ray Team}},
  url = {https://www.povray.org/documentation/view/3.6.1/10/},
}

@TechReport{RenderMan_11_Release_Notes,
    title = {RenderMan 11 Release Notes},
    author = {Pixar},
    type = {Technical Report},
    url = {https://renderman.pixar.com/resources/RenderMan_20/rnotes-11.0.html},
}

@article{rubinWhittedBvh,
  author = {Rubin, Steven M. and Whitted, Turner},
  title = {A 3-dimensional representation for fast rendering of complex scenes},
  year = {1980},
  issue_date = {July 1980},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {14},
  number = {3},
  issn = {0097-8930},
  url = {https://doi.org/10.1145/965105.807479},
  doi = {10.1145/965105.807479},
  abstract = {Hierarchical representations of 3-dimensional objects are both time and space efficient. They typically consist of trees whose branches represent bounding volumes and whose terminal nodes represent primitive object elements (usually polygons). This paper describes a method whereby the object space is represented entirely by a hierarchical data structure consisting of bounding volumes, with no other form of representation. This homogencity allows the visible surface rendering to be performed simply and efficiently.The bounding volumes selected for this algorithm are parallelepipeds oriented to minimize their size. With this representation, any surface can be rendered since in the limit the bounding volumes make up a point representation of the object. The advantage is that the visibility calculations consist only of a search through the data structure to determine the correspondence between terminal level bounding volumes and the current pixel. For ray tracing algorithms, this means that a simplified operation will produce the point of intersection of each ray with the bounding volumes.Memory requirements are minimized by expanding or fetching the lower levels of the hierarchy only when required. Because the viewing process has a single operation and primitive type, the software or hardware chosen to implement the search can be highly optimized for very fast execution.},
  journal = {SIGGRAPH Comput. Graph.},
  month = {jul},
  pages = {110–116},
  numpages = {7},
  keywords = {Visible surface algorithms, Object descriptions, Hierarchical data structures, Computer graphics}
}

@inproceedings{mollerTrumboreFastRayTriangleIntersection,
  author = {M\"{o}ller, Tomas and Trumbore, Ben},
  title = {Fast, minimum storage ray/triangle intersection},
  year = {2005},
  isbn = {9781450378338},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1198555.1198746},
  doi = {10.1145/1198555.1198746},
  abstract = {We present a clean algorithm for determining whether a ray intersects a triangle. The algorithm translates the origin of the ray and then changes the base of that vector which yields a vector (t u v)T, where t is the distance to the plane in which the triangle lies and (u, v) represents the coordinates inside the triangle.One advantage of this method is that the plane equation need not be computed on the fly nor be stored, which can amount to significant memory savings for triangle meshes. As we found our method to be comparable in speed to previous methods, we believe it is the fastest ray/triangle intersection routine for triangles which do not have precomputed plane equations.},
  booktitle = {ACM SIGGRAPH 2005 Courses},
  pages = {7–es},
  keywords = {ray/triangle-intersection, ray tracing, intersection, base transformation},
  location = {Los Angeles, California},
  series = {SIGGRAPH '05}
}

@inproceedings{lauterbach2009GPUbvh,
  title={Fast BVH construction on GPUs},
  author={Lauterbach, Christian and Garland, Michael and Sengupta, Shubhabrata and Luebke, David and Manocha, Dinesh},
  booktitle={Computer Graphics Forum},
  volume={28},
  number={2},
  pages={375--384},
  year={2009},
  organization={Wiley Online Library}
}

@inproceedings{laine2013megakernels,
  title={Megakernels considered harmful: Wavefront path tracing on GPUs},
  author={Laine, Samuli and Karras, Tero and Aila, Timo},
  booktitle={Proceedings of the 5th High-Performance Graphics Conference},
  pages={137--143},
  year={2013}
}

@inproceedings{turkLevoy1994,
  author = {Turk, Greg and Levoy, Marc},
  title = {Zippered polygon meshes from range images},
  year = {1994},
  isbn = {0897916670},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/192161.192241},
  doi = {10.1145/192161.192241},
  abstract = {Range imaging offers an inexpensive and accurate means for digitizing the shape of three-dimensional objects. Because most objects self occlude, no single range image suffices to describe the entire object. We present a method for combining a collection of range images into a single polygonal mesh that completely describes an object to the extent that it is visible from the outside.The steps in our method are: 1) align the meshes with each other using a modified iterated closest-point algorithm, 2) zipper together adjacent meshes to form a continuous surface that correctly captures the topology of the object, and 3) compute local weighted averages of surface positions on all meshes to form a consensus surface geometry.Our system differs from previous approaches in that it is incremental; scans are acquired and combined one at a time. This approach allows us to acquire and combine large numbers of scans with minimal storage overhead. Our largest models contain up to 360,000 triangles. All the steps needed to digitize an object that requires up to 10 range scans can be performed using our system with five minutes of user interaction and a few hours of compute time. We show two models created using our method with range data from a commercial rangefinder that employs laser stripe technology.},
  booktitle = {Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques},
  pages = {311–318},
  numpages = {8},
  keywords = {polygon mesh, range images, structured light range scanner, surface fitting, surface reconstruction},
  series = {SIGGRAPH '94}
}

@inproceedings{whittedGlobalIllumination,
  author = {Whitted, Turner},
  title = {An improved illumination model for shaded display},
  year = {1979},
  isbn = {0897910044},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/800249.807419},
  doi = {10.1145/800249.807419},
  abstract = {To accurately render a scene, global illumination information that affects the intensity of each pixel of the image must be known at the time the intensity is calculated. In a simplified form, this information is stored in a tree of “rays” extending from the viewer to the first surface encountered and from there to other surfaces and to the light sources. The visible surface algorithm creates this tree for each pixel of the display and passes it to the shader. The shader then traverses the tree to determine the intensity of the light received by the viewer. Consideration of all of these factors allows the shader to accurately simulate true reflection, shadows, and refraction as well as the effects simulated by conventional shaders. Anti-aliasing is included as an integral part of the visibility calculations. Surfaces displayed include curved as well as polygonal surfaces.},
  booktitle = {Proceedings of the 6th Annual Conference on Computer Graphics and Interactive Techniques},
  pages = {14},
  keywords = {Computer animation, Computer graphics, Raster displays, Shading, Visible surface algorithms},
  location = {Chicago, Illinois, USA},
  series = {SIGGRAPH '79}
}

@article{whitted2020OriginsOfGlobalIllumination,
    author={Whitted, Turner},
    journal={IEEE Computer Graphics and Applications}, 
    title={Origins of Global Illumination}, 
    year={2020},
    volume={40},
    number={1},
    pages={20-27},
    keywords={Lighting;Reflection;Ray Tracing},
    doi={10.1109/MCG.2019.2957688}
}

@inproceedings{kajiya1986rendering,
  title={The rendering equation},
  author={Kajiya, James T.},
  booktitle={Proceedings of the 13th annual conference on Computer graphics and interactive techniques},
  pages={143--150},
  year={1986}
}

@book{veachMonteCarloLightTransport,
    place={Stanford, Calif},
    title={Robust Monte Carlo Methods for Light Transport Simulation},
    publisher={Stanford University, Department of Computer Science},
    author={Veach, Eric},
    year={1998}
}

@article{reinhardToneMapping,
  author = {Reinhard, Erik and Stark, Michael and Shirley, Peter and Ferwerda, James},
  title = {Photographic tone reproduction for digital images},
  year = {2002},
  issue_date = {July 2002},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {21},
  number = {3},
  issn = {0730-0301},
  url = {https://doi.org/10.1145/566654.566575},
  doi = {10.1145/566654.566575},
  abstract = {A classic photographic task is the mapping of the potentially high dynamic range of real world luminances to the low dynamic range of the photographic print. This tone reproduction problem is also faced by computer graphics practitioners who map digital images to a low dynamic range print or screen. The work presented in this paper leverages the time-tested techniques of photographic practice to develop a new tone reproduction operator. In particular, we use and extend the techniques developed by Ansel Adams to deal with digital images. The resulting algorithm is simple and produces good results for a wide variety of images.},
  journal = {ACM Trans. Graph.},
  month = {jul},
  pages = {267–276},
  numpages = {10},
  keywords = {dynamic range, tone reproduction, zone system}
}

@inproceedings{pbrNeutralToneMapping,
  author = {Lalish, Emmett},
  title = {Neutral Tone Mapping for PBR Color Accuracy},
  year = {2024},
  isbn = {9798400705151},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3641233.3664313},
  doi = {10.1145/3641233.3664313},
  abstract = {On e-commerce websites, interactive 3D product models are side-by-side with sRGB product photos that have been carefully color graded in post to achieve the desired marketing look. For color consistency, e-commerce production requires a tone mapper that faithfully reproduces 3D model material colors on the screen under neutral (grayscale) lighting to match the photos. This allows artists to build 3D models using marking-approved sRGB color swatches without needing to later tweak the material values to make the output align to existing product images. A neutral tone mapper has been developed at the Khronos 3D Commerce working group precisely to address this need. The goal is to standardize it and make it an available option across authoring tools and renderers as an improved alternative to disabling tone mapping entirely when no "look" is desired.},
  booktitle = {ACM SIGGRAPH 2024 Talks},
  articleno = {59},
  numpages = {2},
  keywords = {color grading, e-commerce, physically-based rendering, tone mapping},
  location = {Denver, CO, USA},
  series = {SIGGRAPH '24}
}

@article{restir,
author = {Bitterli, Benedikt and Wyman, Chris and Pharr, Matt and Shirley, Peter and Lefohn, Aaron and Jarosz, Wojciech},
title = {Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3386569.3392481},
doi = {10.1145/3386569.3392481},
abstract = {Efficiently rendering direct lighting from millions of dynamic light sources using Monte Carlo integration remains a challenging problem, even for off-line rendering systems. We introduce a new algorithm---ReSTIR---that renders such lighting interactively, at high quality, and without needing to maintain complex data structures. We repeatedly resample a set of candidate light samples and apply further spatial and temporal resampling to leverage information from relevant nearby samples. We derive an unbiased Monte Carlo estimator for this approach, and show that it achieves equal-error 6\texttimes{}-60\texttimes{} faster than state-of-the-art methods. A biased estimator reduces noise further and is 35\texttimes{}-65\texttimes{} faster, at the cost of some energy loss. We implemented our approach on the GPU, rendering complex scenes containing up to 3.4 million dynamic, emissive triangles in under 50 ms per frame while tracing at most 8 rays per pixel.},
journal = {ACM Trans. Graph.},
month = {aug},
articleno = {148},
numpages = {17},
keywords = {reservoir sampling, resampled importance sampling, real-time rendering, photorealistic rendering}
}


@article{restirAdvancements,
author = {Ouyang, Y. and Liu, S. and Kettunen, M. and Pharr, M. and Pantaleoni, J.},
title = {ReSTIR GI: Path Resampling for Real-Time Path Tracing},
journal = {Computer Graphics Forum},
volume = {40},
number = {8},
pages = {17-29},
keywords = {CCS Concepts, • Computing methodologies → Rendering, Ray tracing},
doi = {https://doi.org/10.1111/cgf.14378},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14378},
abstract = {Abstract Even with the advent of hardware-accelerated ray tracing in modern GPUs, only a small number of rays can be traced at each pixel in real-time applications. This presents a significant challenge for path tracing, even when augmented with state-of-the art denoising algorithms. While the recently-developed ReSTIR algorithm [BWP∗20] enables high-quality renderings of scenes with millions of light sources using just a few shadow rays at each pixel, there remains a need for effective algorithms to sample indirect illumination. We introduce an effective path sampling algorithm for indirect lighting that is suitable to highly parallel GPU architectures. Building on the screen-space spatio-temporal resampling principles of ReSTIR, our approach resamples multi-bounce indirect lighting paths obtained by path tracing. Doing so allows sharing information about important paths that contribute to lighting both across time and pixels in the image. The resulting algorithm achieves a substantial error reduction compared to path tracing: at a single sample per pixel every frame, our algorithm achieves MSE improvements ranging from 9.3× to 166× in our test scenes. In conjunction with a denoiser, it leads to high-quality path traced global illumination at real-time frame rates on modern GPUs.},
year = {2021}
}

@article{restirGeneralized,
  title={Generalized resampled importance sampling: Foundations of restir},
  author={Lin, Daqi and Kettunen, Markus and Bitterli, Benedikt and Pantaleoni, Jacopo and Yuksel, Cem and Wyman, Chris},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={4},
  pages={1--23},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{restirArea,
  title         = {Area ReSTIR: Resampling for Real-Time Defocus and Antialiasing},
  author        = {Zhang, Song and Lin, Daqi and Kettunen, Markus and Yuksel, Cem and Wyman, Chris},
  month         = {July},
  booktitle     = {ACM Transactions on Graphics (SIGGRAPH)},
  year          = {2024},
  volume        = {43},
  number        = {4},
  doi           = {10.1145/3658210},
}

@article{muller2021real,
author = {M\"{u}ller, Thomas and Rousselle, Fabrice and Nov\'{a}k, Jan and Keller, Alexander},
title = {Real-time neural radiance caching for path tracing},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3450626.3459812},
doi = {10.1145/3450626.3459812},
abstract = {We present a real-time neural radiance caching method for path-traced global illumination. Our system is designed to handle fully dynamic scenes, and makes no assumptions about the lighting, geometry, and materials. The data-driven nature of our approach sidesteps many difficulties of caching algorithms, such as locating, interpolating, and updating cache points. Since pretraining neural networks to handle novel, dynamic scenes is a formidable generalization challenge, we do away with pretraining and instead achieve generalization via adaptation, i.e. we opt for training the radiance cache while rendering. We employ self-training to provide low-noise training targets and simulate infinite-bounce transport by merely iterating few-bounce training updates. The updates and cache queries incur a mild overhead---about 2.6ms on full HD resolution---thanks to a streaming implementation of the neural network that fully exploits modern hardware. We demonstrate significant noise reduction at the cost of little induced bias, and report state-of-the-art, real-time performance on a number of challenging scenarios.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {36},
numpages = {16},
keywords = {deep learning, neural networks, path tracing, radiance caching, real-time, rendering}
}

@article{blockwise-multi-order-regresssion-for-rt-pt,
author = {Koskela, Matias and Immonen, Kalle and M\"{a}kitalo, Markku and Foi, Alessandro and Viitanen, Timo and J\"{a}\"{a}skel\"{a}inen, Pekka and Kultala, Heikki and Takala, Jarmo},
title = {Blockwise Multi-Order Feature Regression for Real-Time Path-Tracing Reconstruction},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {5},
issn = {0730-0301},
url = {https://doi.org/10.1145/3269978},
doi = {10.1145/3269978},
abstract = {Path tracing produces realistic results including global illumination using a unified simple rendering pipeline. Reducing the amount of noise to imperceptible levels without post-processing requires thousands of samples per pixel (spp), while currently it is only possible to render extremely noisy 1&nbsp;spp frames in real time with desktop GPUs. However, post-processing can utilize feature buffers, which contain noise-free auxiliary data available in the rendering pipeline. Previously, regression-based noise filtering methods have only been used in offline rendering due to their high computational cost. In this article we propose a novel regression-based reconstruction pipeline, called Blockwise Multi-Order Feature Regression (BMFR), tailored for path-traced 1 spp inputs that runs in real time. The high speed is achieved with a fast implementation of augmented QR factorization and by using stochastic regularization to address rank-deficient feature data. The proposed algorithm is 1.8\texttimes{} faster than the previous state-of-the-art real-time path-tracing reconstruction method while producing better quality frame sequences.},
journal = {ACM Trans. Graph.},
month = {jun},
articleno = {138},
numpages = {14},
keywords = {Path tracing, real-time, reconstruction, regression}
}

@online{conventionalGaussianDenoise,
  title = {Fast glsl deNoise spatial filter},
  author = {Morrone, Michele},
  year = {2021},
  month = {November},
  url = {https://github.com/BrutPitt/glslSmartDeNoise},
  lastaccessed = "August 20, 2024",
}

@inproceedings{buadesNLMDenoising,
  author={Buades, A. and Coll, B. and Morel, J.-M.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={A non-local algorithm for image denoising}, 
  year={2005},
  volume={2},
  number={},
  pages={60-65 vol. 2},
  keywords={Image denoising;Noise reduction;Algorithm design and analysis;Smoothing methods;Wiener filter;Filtering;Noise measurement;Digital images;Pixel;White noise},
  doi={10.1109/CVPR.2005.38}
}

@misc{openImageDenoise,
  author = {Attila T. {\'A}fra},
  title  = {{Intel\textsuperscript{\textregistered} Open Image Denoise}},
  year   = {2024},
  note   = {\url{https://www.openimagedenoise.org}}
}

@online{oidnWeb,
  title = {Open Image Denoise on the Web},
  author = {Shen, Yi},
  year = {2024},
  month = {August},
  url = {https://github.com/pissang/oidn-web},
  lastaccessed = "August 20, 2024",
}


@book{luebke2003level,
  title={Level of detail for 3D graphics},
  author={Luebke, David},
  year={2003},
  publisher={Morgan Kaufmann}
}

@misc{nvidiaDlss,
  author = {{NVIDIA Corporation}},
  title = {NVIDIA DLSS},
  url = {https://www.nvidia.com/en-us/geforce/technologies/dlss/},
}

@misc{nvidiaRtxRayTracing,
  author = {{NVIDIA Corporation}},
  title = {NVIDIA RTX Ray Tracing},
  url = {https://developer.nvidia.com/rtx/ray-tracing},
  lastaccessed = "July 10, 2024",
}

@misc{appleM3GpuAdvancements,
  author = {{Apple Developer}},
  title = "Explore GPU advancements in M3 and A17 Pro - Tech Talks",
  url = "https://developer.apple.com/videos/play/tech-talks/111375",
  year = {2023},
  lastaccessed = "July 10, 2024",
}

@article{greene1986environment,
  title={Environment mapping and other applications of world projections},
  author={Greene, Ned},
  journal={IEEE computer graphics and Applications},
  volume={6},
  number={11},
  pages={21--29},
  year={1986},
  publisher={IEEE}
}

@article{bavoil2008ssao,
  title={Screen space ambient occlusion},
  author={Bavoil, Louis and Sainz, Miguel},
  journal={NVIDIA developer information: http://developer.nvidia.com},
  volume={6},
  number={2},
  year={2008}
}

@inproceedings{screenSpaceReflectionsStackowiak,
  author = {Stachowiak, Tomasz},
  title = {Advances in real time rendering, part I, Stochastic Screen-Space Reflections},
  year = {2015},
  isbn = {9781450336345},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2776880.2787701},
  doi = {10.1145/2776880.2787701},
  booktitle = {ACM SIGGRAPH 2015 Courses},
  articleno = {1},
  location = {Los Angeles, California},
  series = {SIGGRAPH '15}
}

@Inbook{hybridRenderingBarreBrisebois2019,
  author="Barr{\'e}-Brisebois, Colin
  and Hal{\'e}n, Henrik
  and Wihlidal, Graham
  and Lauritzen, Andrew
  and Bekkers, Jasper
  and Stachowiak, Tomasz
  and Andersson, Johan",
  editor="Haines, Eric
  and Akenine-M{\"o}ller, Tomas",
  title="Hybrid Rendering for Real-Time Ray Tracing",
  bookTitle="Ray Tracing Gems: High-Quality and Real-Time Rendering with DXR and Other APIs",
  year="2019",
  publisher="Apress",
  address="Berkeley, CA",
  pages="437--473",
  abstract="This chapter describes the rendering pipeline developed for PICA PICA, a real-time ray tracing experiment featuring self-learning agents in a procedurally assembled world. PICA PICA showcases a hybrid rendering pipeline in which rasterization, compute, and ray tracing shaders work together to enable real-time visuals approaching the quality of offline path tracing.",
  isbn="978-1-4842-4427-2",
  doi="10.1007/978-1-4842-4427-2_25",
  url="https://doi.org/10.1007/978-1-4842-4427-2_25"
}

@inproceedings{gautron2020rtao,
  author = {Gautron, Pascal},
  title = {Real-Time Ray-Traced Ambient Occlusion of Complex Scenes using Spatial Hashing},
  year = {2020},
  isbn = {9781450379717},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3388767.3407375},
  doi = {10.1145/3388767.3407375},
  abstract = {Ambient occlusion is often approximated in real-time using screen-space techniques, leading to visible artifacts. Raytracing provides a unique way to increase the rendering fidelity by accurately sampling the distance to the surrounding objects, but it introduces sampling noise. We propose a real-time ray-traced ambient occlusion technique in which noise is filtered in world space. Using extended spatial hashing for efficient storage, multiresolution AO evaluation and ad-hoc filtering, we demonstrate the usability of our technique as a production feature usable in CAD viewports with scenes comprising hundreds of millions of polygons.},
  booktitle = {ACM SIGGRAPH 2020 Talks},
  articleno = {5},
  numpages = {2},
  location = {Virtual Event, USA},
  series = {SIGGRAPH '20}
}

@inproceedings{ritschel2009ssdo,
  author = {Ritschel, Tobias and Grosch, Thorsten and Seidel, Hans-Peter},
  title = {Approximating dynamic global illumination in image space},
  year = {2009},
  isbn = {9781605584294},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1507149.1507161},
  doi = {10.1145/1507149.1507161},
  abstract = {Physically plausible illumination at real-time framerates is often achieved using approximations. One popular example is ambient occlusion (AO), for which very simple and efficient implementations are used extensively in production. Recent methods approximate AO between nearby geometry in screen space (SSAO). The key observation described in this paper is, that screen-space occlusion methods can be used to compute many more types of effects than just occlusion, such as directional shadows and indirect color bleeding. The proposed generalization has only a small overhead compared to classic SSAO, approximates direct and one-bounce light transport in screen space, can be combined with other methods that simulate transport for macro structures and is visually equivalent to SSAO in the worst case without introducing new artifacts. Since our method works in screen space, it does not depend on the geometric complexity. Plausible directional occlusion and indirect lighting effects can be displayed for large and fully dynamic scenes at real-time frame rates.},
  booktitle = {Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games},
  pages = {75–82},
  numpages = {8},
  keywords = {radiosity, global illumination, constant time},
  location = {Boston, Massachusetts},
  series = {I3D '09}
}

@article{ssim,
  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  keywords={Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi={10.1109/TIP.2003.819861}
}

@InProceedings{lpips,
author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A. and Shechtman, Eli and Wang, Oliver},
title = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@article{remoteRendering,
  author = {Shi, Shu and Hsu, Cheng-Hsin},
  title = {A Survey of Interactive Remote Rendering Systems},
  year = {2015},
  issue_date = {July 2015},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {47},
  number = {4},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/2719921},
  doi = {10.1145/2719921},
  abstract = {Remote rendering means rendering 3D graphics on a computing device and displaying the results on another computing device connected through a network. The concept was originally developed for sharing computing resources remotely. It has been receiving increasing attention from researchers in both academia and industry in recent years due to the proliferation of cloud computing and mobile devices. In this article, we survey the interactive remote rendering systems proposed in the literature, analyze how to improve the state of the art, and summarize the related technologies. The readers of this article will understand the history of remote rendering systems and obtain some inspirations of the future research directions in this area.},
  journal = {ACM Comput. Surv.},
  month = {may},
  articleno = {57},
  numpages = {29},
  keywords = {video streaming, distributed rendering, cloud rendering, cloud games, QoS, QoE, Cloud computing}
}

@article{randomnessCryptography,
  author={Gennaro, Rosario},
  journal={IEEE Security \& Privacy}, 
  title={Randomness in cryptography}, 
  year={2006},
  volume={4},
  number={2},
  pages={64-67},
  keywords={Cryptography;Entropy;Random processes;Application software;Computer science;Computer security;Privacy;randomness;predictable;cryptography;nonce},
  doi={10.1109/MSP.2006.49}
}

@online{cloudflareLavaRand,
  title = {LavaRand in Production},
  author = {Liebow-Feeser, Joshua},
  month = {June},
  year = {2017},
  url = {https://blog.cloudflare.com/randomness-101-lavarand-in-production},
  lastaccessed = "June 27, 2024",
}

@article{rngMersenneTwister,
    author = {Matsumoto, Makoto and Nishimura, Takuji},
    title = {Mersenne twister: a 623-dimensionally equidistributed uniform pseudo-random number generator},
    year = {1998},
    issue_date = {Jan. 1998},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {8},
    number = {1},
    issn = {1049-3301},
    url = {https://doi.org/10.1145/272991.272995},
    doi = {10.1145/272991.272995},
    abstract = {A new algorithm called Mersenne Twister (MT) is proposed for generating uniform pseudorandom numbers. For a particular choice of parameters, the algorithm provides a super astronomical period of 219937 −1 and 623-dimensional equidistribution up to 32-bit accuracy, while using a working area of only 624 words. This is a new variant of the previously proposed generators, TGFSR, modified so as to admit a Mersenne-prime period. The characteristic polynomial has many terms. The distribution up to v bits accuracy for 1 ≤ v ≤ 32 is also shown to be good. An algorithm is also given that checks the primitivity of the characteristic polynomial of MT with computational complexity O(p2) where  p is the degree of the polynomial.We implemented this generator in portable C-code. It passed several stringent statistical tests, including diehard. Its speed is comparable to other modern generators. Its merits are due to the efficient algorithms that are unique to polynomial calculations over the two-element field.},
    journal = {ACM Trans. Model. Comput. Simul.},
    month = {jan},
    pages = {3–30},
    numpages = {28},
    keywords = {k-distribution, m-sequences, GFSR, MT19937, Mersenne primes, Mersenne twister, TGFSR, finite fields, incomplete array, inversive-decimation method, multiple-recursive matrix method, primitive polynomials, random number generation, tempering}
}

@article{marsaglia2003xorshift,
    title={Xorshift rngs},
    author={Marsaglia, George},
    journal={Journal of Statistical software},
    volume={8},
    pages={1--6},
    year={2003}
}

@article{o2014pcg,
  title={PCG: A family of simple fast space-efficient statistically good algorithms for random number generation},
  author={O'Neill, Melissa E.},
  journal={ACM Transactions on Mathematical Software},
  year={2014}
}

@mastersthesis{dotson2022dynamicaljs,
    title = {Dynamical.JS: A composable framework for online exploratory visualization of arbitrarily-complex multivariate networks},
    author = {Dotson, Robert L.},
    school = {Harvard University Division of Continuing Education},
    year = {2022}
}


@article{Bohak_Kovalskyi_Linev_Mrak_Tadel_Strban_Tadel_Yagil_2024,
    title={RenderCore – a new WebGPU-based rendering engine for Root-eve},
    volume={295},
    DOI={10.1051/epjconf/202429503035},
    journal={EPJ Web of Conferences},
    author={Bohak, Ciril and Kovalskyi, Dmytro and Linev, Sergey and Mrak Tadel, Alja and Strban, Sebastien and Tadel, Matevž and Yagil, Avi},
    year={2024},
    pages={03035}
}

@article{kimmersdorfer2023webgpu,
    title={WebGPU for Scalable Client-Side Aggregate Visualization},
    author={Kimmersdorfer, Gerald and Wolf, Dominik and Waldner, Manuela},
    journal={Proceedings of Eurographics - The European Association for Computer Graphics},
    year={2023},
    pages={1--3},
    publisher={The European Association for Computer Graphics}
}

@article{webGPUWebGis,
  AUTHOR = {Usta, Ziya},
  TITLE = {WebGPU: A new Graphic API for 3D WebGIS Applications},
  JOURNAL = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  VOLUME = {XLVIII-4/W9-2024},
  YEAR = {2024},
  PAGES = {377--382},
  URL = {https://isprs-archives.copernicus.org/articles/XLVIII-4-W9-2024/377/2024/},
  DOI = {10.5194/isprs-archives-XLVIII-4-W9-2024-377-2024}
}

@inproceedings{fusionRenderWebGPU,
  author = {Bi, Weichen and Ma, Yun and Han, Yudong and Chen, Yifan and Tian, Deyu and Du, Jiaqi},
  title = {FusionRender: Harnessing WebGPU's Power for Enhanced Graphics Performance on Web Browsers},
  year = {2024},
  isbn = {9798400701719},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3589334.3645395},
  doi = {10.1145/3589334.3645395},
  abstract = {Graphics rendering on web browsers serves as the foundation for numerous web applications. Compared with the widely employed WebGL, the next-generation web graphics API, WebGPU, demonstrates an enhanced capacity to adapt to modern GPU features, boasting more significant potential. However, our experiment shows that the performance of current graphics rendering frameworks based on WebGPU lags behind those built on WebGL. Such discrepancy primarily arises from an incomplete alignment with WebGPU's distinctive features. The individual rendering of each graphic leads to redundant communication between the CPU and GPU. To enhance the graphics performance on the web, we introduce the FusionRender to harness the power of WebGPU. To mitigate redundant communication, FusionRender assigns a unique signature to each object and employs these signatures for grouping, enabling the consolidation of graphics rendering whenever possible. In simulated experiments involving the rendering of multiple objects, FusionRender improves the rendering performance by 29.3\%-122.1\% compared with the existing optimal baseline. In real cases with more complex features, performance improvement ranges from 9.4\% to 39.7\%. Additionally, FusionRender exhibits robust performance enhancement across various devices and browsers.},
  booktitle = {Proceedings of the ACM on Web Conference 2024},
  pages = {2890–2901},
  numpages = {12},
  keywords = {graphics, performance optimization, web applications, webgpu},
  location = {Singapore, Singapore},
  series = {WWW '24}
}

@article{fransson2023performance,
  title = {Performance comparison of WebGPU and WebGL in the Godot game engine},
  author = {Fransson, Emil and Hermansson, Jonatan},
  year = {2023},
  url = {https://urn.kb.se/resolve?urn=urn:nbn:se:bth-24706},
  type = {Dissertation}
}

@article{CHICKERUR2024919,
    title = {WebGL vs. WebGPU: A Performance Analysis for Web 3.0},
    journal = {Procedia Computer Science},
    volume = {233},
    pages = {919-928},
    year = {2024},
    note = {5th International Conference on Innovative Data Communication Technologies and Application (ICIDCA 2024)},
    issn = {1877-0509},
    doi = {https://doi.org/10.1016/j.procs.2024.03.281},
    url = {https://www.sciencedirect.com/science/article/pii/S1877050924006410},
    author = {Satyadhyan Chickerur and Sankalp Balannavar and Pranali Hongekar and Aditi Prerna and Soumya Jituri},
    keywords = {WebGL, WebGPU, Rendering, Performance analysis, Web3.0},
    abstract = {This study investigates web 3.0 heterogeneous computing with webGL, webGPU, and IPFS. The primary focus is on the benefits of utilising these technologies to enhance the functionality and performance of web 3.0 applications. The study investigates web 3.0 as it currently exists and the constraints that developers face due to graphic, computational, and storage capabilities. According to the findings, incorporating webGL and webGPU can considerably increase user experience, speed, efficacy, and decentralization. Finally, this study summarizes the importance of continuing research in this subject, particularly with relation to platform interoperability and the future prospects of heterogeneous computing on web 3.0 via graphical APIs.}
}

@online{cycles,
  title = {Cycles: Open Source Production Rendering},
  author = {{Blender Foundation}},
  year = {2024},
  url = {https://www.cycles-renderer.org/},
  lastaccessed = "August 1, 2024",
}

@Book{Pharr_Physically_Based_Rendering_2023,
  title = {Physically Based Rendering: From Theory to Implementation},
  author = {Pharr, Matt and Jakob, Wenzel and Humphreys, Greg},
  year = {2023},
  publisher = {The MIT Press}
}

@book{lambert1760photometria,
  title={Photometria},
  author={Lambert, Johann Heinrich},
  year={1760}
}

@book{kalos2009monte,
  title={Monte carlo methods},
  author={Kalos, Malvin H and Whitlock, Paula A},
  year={2009},
  publisher={John Wiley \& Sons}
}

@Inbook{ipr,
  author="Stjepandi{\'{c}}, Josip
  and Liese, Harald
  and Trappey, Amy J. C.",
  editor="Stjepandi{\'{c}}, Josip
  and Wognum, Nel
  and J.C. Verhagen, Wim",
  title="Intellectual Property Protection",
  bookTitle="Concurrent Engineering in the 21st Century: Foundations, Developments and Challenges",
  year="2015",
  publisher="Springer International Publishing",
  address="Cham",
  pages="521--551",
  abstract="With the growth of the knowledge-based economy, intellectual property right (IPR) is recognized as a key factor to develop and protect strategic competitiveness and innovation of an enterprise. The increasing degree of collaboration in global relationships, ubiquitous digital communication techniques as well as tough competition has lead to an increasing importance of intellectual property protection (IPP) for enterprises. Since the law as well as ethical principles are not always adhered to, there are increasingly activities outside legal understanding. This situation is exacerbated in the context of rising crime through the misuse of modern ICT technologies (``Cyber Crime'') and now employs extensively state authorities. Piracy, counterfeits and unwanted know-how drain pose a significant problem for each market leader. Intellectual property is stored in product data too. Especially modern parametric and feature-based 3D-CAD systems have been enhanced towards acquiring, representing, processing and distributing knowledge to support knowledge-based engineering (KBE) within virtual product creation. However, it is very easy to exchange huge amounts of product data within a virtual enterprise that comprises an enterprise with its supplier network. There is an enormous threat that intellectual property could fall into the wrong hands and badly jeopardize the existence of the related company. This chapter contains an analysis of this conflict area, a picture of the legal framework, a discussion on the need for action in supply chain networks and attempts by research and development as well as best practices in industry for various aspects of IPP in the context of concurrent engineering (CE).",
  isbn="978-3-319-13776-6",
  doi="10.1007/978-3-319-13776-6_18",
  url="https://doi.org/10.1007/978-3-319-13776-6_18"
}

@inproceedings{marjudi2010StepIgesreview,
  title={A Review and Comparison of IGES and STEP},
  author={Marjudi, Suziyanti and Amran, MF Mohd and Abdullah, Khairul Annuar and Widyarto, Setyawan and Majid, NA Abdul and Sulaiman, Riza},
  booktitle={Proceedings Of World Academy Of Science, Engineering And Technology},
  volume={62},
  pages={1013--1017},
  year={2010}
}

@inproceedings{cloudLatency,
  author = {Corneo, Lorenzo and Eder, Maximilian and Mohan, Nitinder and Zavodovski, Aleksandr and Bayhan, Suzan and Wong, Walter and Gunningberg, Per and Kangasharju, Jussi and Ott, J\"{o}rg},
  title = {Surrounded by the Clouds: A Comprehensive Cloud Reachability Study},
  year = {2021},
  isbn = {9781450383127},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3442381.3449854},
  doi = {10.1145/3442381.3449854},
  abstract = {In the early days of cloud computing, datacenters were sparsely deployed at distant locations far from end-users with high end-to-end communication latency. However, today’s cloud datacenters have become more geographically spread, the bandwidth of the networks keeps increasing, pushing the end-users latency down. In this paper, we provide a comprehensive cloud reachability study as we perform extensive global client-to-cloud latency measurements towards 189 datacenters from all major cloud providers. We leverage the well-known measurement platform RIPE Atlas, involving up to 8500 probes deployed in heterogeneous environments, e.g., home and offices. Our goal is to evaluate the suitability of modern cloud environments for various current and predicted applications. We achieve this by comparing our latency measurements against known human perception thresholds and are able to draw inferences on the suitability of current clouds for novel applications, such as augmented reality. Our results indicate that the current cloud coverage can easily support several latency-critical applications, like cloud gaming, for the majority of the world’s population.},
  booktitle = {Proceedings of the Web Conference 2021},
  pages = {295–304},
  numpages = {10},
  keywords = {Cloud reachability, Internet measurements},
  location = {Ljubljana, Slovenia},
  series = {WWW '21}
}

@inproceedings{oren1994generalization,
  title={Generalization of Lambert's reflectance model},
  author={Oren, Michael and Nayar, Shree K},
  booktitle={Proceedings of the 21st annual conference on Computer graphics and interactive techniques},
  pages={239--246},
  year={1994}
}

@article{goral1984modeling,
  title={Modeling the interaction of light between diffuse surfaces},
  author={Goral, Cindy M. and Torrance, Kenneth E. and Greenberg, Donald P. and Battaile, Bennett},
  journal={ACM SIGGRAPH computer graphics},
  volume={18},
  number={3},
  pages={213--222},
  year={1984},
  publisher={ACM New York, NY, USA}
}

@article{Jakob2020DrJit,
  author = {Wenzel Jakob and Sébastien Speierer and Nicolas Roussel and Delio Vicini},
  title = {Dr.Jit: A Just-In-Time Compiler for Differentiable Rendering},
  journal = {Transactions on Graphics (Proceedings of SIGGRAPH)},
  volume = {41},
  number = {4},
  year = {2022},
  month = jul,
  doi = {10.1145/3528223.3530099}
}

@online{mitsubaWavefrontVsMegakernel,
  title = {GPU Rendering not that much faster},
  author = {Wenzel Jakob},
  year = {2024},
  month = {April},
  url = {https://github.com/mitsuba-renderer/mitsuba2/issues/72#issuecomment-610631631},
  lastaccessed = "August 20, 2024",
}

@article{wavefrontComparisonInTableA5,
  title = {Path guiding for wavefront path tracing: A memory efficient approach for GPU path tracers},
  journal = {Computers \& Graphics},
  volume = {121},
  pages = {103945},
  year = {2024},
  issn = {0097-8493},
  doi = {https://doi.org/10.1016/j.cag.2024.103945},
  url = {https://www.sciencedirect.com/science/article/pii/S0097849324000803},
  author = {Bora Yalçıner and Ahmet Oğuz Akyüz},
  keywords = {Graphics processors, Monte Carlo rendering, Path tracing, Path guiding},
  abstract = {We propose a path-guiding algorithm to be incorporated into the wavefront style of path tracers (WFPTs). As WFPTs are primarily implemented on graphics processing units (GPUs), the proposed method aims to leverage the capabilities of the GPUs and reduce the hierarchical data structure and memory usage typically required for such techniques. To achieve this, our algorithm only stores the radiant exitance on a single global sparse voxel octree (SVO) data structure. Probability density functions required to guide the rays are generated on-the-fly using this data structure. The proposed approach reduces the scene-related persistent memory requirements compared to other path-guiding techniques while producing similar or better results depending on scene characteristics. To our knowledge, our algorithm is the first one that incorporates path guiding into a WFPT.}
}

@article{surveyOnOptimizationTechniquesForGPU,
  author = {Hijma, Pieter and Heldens, Stijn and Sclocco, Alessio and van Werkhoven, Ben and Bal, Henri E.},
  title = {Optimization Techniques for GPU Programming},
  year = {2023},
  issue_date = {November 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {55},
  number = {11},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3570638},
  doi = {10.1145/3570638},
  abstract = {In the past decade, Graphics Processing Units have played an important role in the field of high-performance computing and they still advance new fields such as IoT, autonomous vehicles, and exascale computing. It is therefore important to understand how to extract performance from these processors, something that is not trivial. This survey discusses various optimization techniques found in 450 articles published in the last 14 years. We analyze the optimizations from different perspectives which shows that the various optimizations are highly interrelated, explaining the need for techniques such as auto-tuning.},
  journal = {ACM Comput. Surv.},
  month = {mar},
  articleno = {239},
  numpages = {81},
  keywords = {Survey, GPU, optimization, optimization techniques, performance bottleneck}
}

@misc{dabrovic2002sponza,
  title={Sponza atrium},
  author={Dabrovic, Marko},
  year={2002}
}

@online{Harrysson2019,
  title = {MaterialX Physically-Based Shading Nodes Introduction},
  author = {Harrysson, Niklas and Smythe, Doug and Stone, Jonathan},
  month = {July},
  year = {2019},
  url = {https://materialx.org/assets/MaterialX.v1.37REV2.PBRSpec.pdf},
  lastaccessed = "May 10, 2024",
}

@article{heitz2018sampling,
  title={Sampling the ggx distribution of visible normals},
  author={Heitz, Eric},
  journal={Journal of Computer Graphics Techniques (JCGT)},
  volume={7},
  number={4},
  pages={1--13},
  year={2018}
}

@article{walter2007microfacet,
  title={Microfacet Models for Refraction through Rough Surfaces.},
  author={Walter, Bruce and Marschner, Stephen R and Li, Hongsong and Torrance, Kenneth E},
  journal={Rendering techniques},
  volume={2007},
  pages={18th},
  year={2007}
}

@inproceedings{disney2012pbr,
  title={Physically-based Shading at Disney},
  author={Burley, Brent},
  organization={Walt Disney Animation Studios},
  booktitle={Acm Siggraph},
  volume={2012},
  pages={1--7},
  year={2012},
}

@online{renderManDisneyPbrDocs,
  title = {RenderMan PxrDisney Material},
  author = {Pixar},
  month = {July},
  year = {2015},
  url = {https://renderman.pixar.com/resources/RenderMan_20/PxrDisney.html},
  lastaccessed = "July 29, 2024",
}

@online{autodeskStandardSurface,
  title = {Autodesk Standard Surface},
  author = {Iliyan Georgiev and Jamie Portsmouth and Zap Andersson and Adrien Herubel and Alan King and Shinji Ogaki and Frederic Servant},
  month = {February},
  year = {2023},
  url = {https://autodesk.github.io/standard-surface/},
  lastaccessed = "July 29, 2024",
}

@online{adobeStandardMaterial,
  title = {Adobe Standard Material},
  author = {Adobe},
  month = {October},
  year = {2021},
  url = {https://helpx.adobe.com/substance-3d-general/adobe-standard-material/asm-specifications.html},
  lastaccessed = "July 29, 2024",
}

@online{dspbrModel,
  title = {Enterprise PBR Shading Model},
  author = {{Dassault Systèmes}},
  month = {June},
  year = {2024},
  url = {https://dassaultsystemes-technology.github.io/EnterprisePBRShadingModel/spec-2025x.md.html},
  lastaccessed = "July 29, 2024",
}

@techreport{openPBRSpec,
  author = {Zap Andersson and Paul Edmondson and Julien Guertault and Adrien Herubel and Alan King and Peter Kutz and Andréa Machizaud and Jamie Portsmouth and Frédéric Servant and Jonathan Stone},
  title = {{O}pen{PBR} {S}urface Specification},
  institution = {Academy Software Foundation ({ASWF})},
  year = {2024},
  url = {https://academysoftwarefoundation.github.io/OpenPBR/}
}

@online{openPBR1Dot0Release,
  author = {{Academy Software Foundation (ASWF)}},
  title = {Academy Software Foundation Releases OpenPBR 1.0},
  month= {June},
  year = {2024},
  url = {https://www.aswf.io/blog/academy-software-foundation-releases-openpbr-1-0/},
  lastaccessed = "July 14, 2024",
}

@online{omniverseOpenPBR,
  author = {Langlands, Anders},
  title = {Unlock Seamless Material Interchange for Virtual Worlds with OpenUSD, MaterialX, and OpenPBR},
  month = {March},
  year = {2024},
  url = {https://developer.nvidia.com/blog/unlock-seamless-material-interchange-for-virtual-worlds-with-openusd-materialx-and-openpbr/},
  lastaccessed = "July 14, 2024",
}

@online{blenderOpenPBRInspiration,
  author = {Langlands, Anders},
  title = {Unlock Seamless Material Interchange for Virtual Worlds with OpenUSD, MaterialX, and OpenPBR},
  month = {November},
  year = {2023},
  url = {https://docs.blender.org/manual/en/4.0/render/shader_nodes/shader/principled.html},
  lastaccessed = "July 14, 2024",
}

@online{SafariWebGPUSupport,
  title = {WebGPU now available for testing in Safari Technology Preview},
  author = {Wyrzykowski, Mike},
  month = {December},
  year = {2023},
  url = {https://webkit.org/blog/14879/webgpu-now-available-for-testing-in-safari-technology-preview/},
  lastaccessed = "May 30, 2024",
}

@online{webKitWebGPUImplementation,
  title = {WebKit source WebGPU implementation},
  author = {Apple},
  month = {July},
  year = {2024},
  url = {https://github.com/WebKit/WebKit/tree/main/Source/WebGPU},
  lastaccessed = "July 26, 2024",
}

@online{FirefoxWebGPUSupport,
  title = {Mozilla Platform GFX WebGPU},
  author = {Mozilla},
  month = {April},
  year = {2023},
  url = {https://wiki.mozilla.org/Platform/GFX/WebGPU},
  lastaccessed = "May 30, 2024",
}

@online{wgpuImplementation,
  title = {wgpu source code},
  author = {{gfx-rs}},
  month = {July},
  year = {2024},
  url = {https://github.com/gfx-rs/wgpu},
  lastaccessed = "July 26, 2024",
}

@online{nagaImplementation,
  title = {Naga source code},
  author = {{gfx-rs}},
  month = {October},
  year = {2023},
  url = {https://github.com/gfx-rs/naga},
  lastaccessed = "August 5, 2024",
}

@online{wgpuStandardDeviation,
  title = {Differences between our subgroup implementation and the WebGPU proposal},
  author = {{gfx-rs}},
  month = {April},
  year = {2024},
  url = {https://github.com/gfx-rs/wgpu/issues/5555},
  lastaccessed = "July 26, 2024",
}

@online{ChromeWebGPUSupport,
  title = {Chrome Platform Status: WebGPU},
  author = {Google},
  month = {April},
  year = {2023},
  url = {https://chromestatus.com/feature/6213121689518080},
  lastaccessed = "May 30, 2024",
}

@online{ChromeAndroidWebGPUSupport,
  title = {Chrome Platform Status: WebGPU on Android},
  author = {Google},
  month = {January},
  year = {2024},
  url = {https://chromestatus.com/feature/5119617865613312},
  lastaccessed = "May 30, 2024",
}

@online{dawnImplementation,
  title = {Dawn source code},
  author = {Google},
  month = {July},
  year = {2024},
  url = {https://dawn.googlesource.com/dawn},
  lastaccessed = "July 26, 2024",
}

@online{babylonJSWebsite,
  title={Babylon.js},
  author = {Babylon.js},
  month = {July},
  year = {2024},
  url = {https://www.babylonjs.com/},
  lastaccessed = "July 28, 2024",
}

@online{BabylonJSWebGPUSupport,
  title = {WebGPU Support},
  author = {Babylon.js},
  month = {October},
  year = {2022},
  url = {https://doc.babylonjs.com/setup/support/webGPU},
  lastaccessed = "May 30, 2024",
}

@online{threeJSWebsite,
  title = {Three.js},
  author = {{Three.js}},
  month = {July},
  year = {2024},
  url = {https://threejs.org/},
  lastaccessed = "July 28, 2024",
}

@online{ThreeJSWebGPUSupport,
  title = {Three.js WebGPURenderer.js},
  author = {{Three.js}},
  month = {January},
  year = {2024},
  url = {https://github.com/mrdoob/three.js/blob/de367cb2e866d4ffc9bd4b23dddd137a93ee65ba/examples/jsm/renderers/webgpu/WebGPURenderer.js},
  lastaccessed = "May 30, 2024",
}

@online{ThreeJSShadingLanguage,
  title = {Three.js Shading Language},
  author = {{Three.js}},
  month = {August},
  year = {2024},
  url = {https://github.com/mrdoob/three.js/wiki/Three.js-Shading-Language},
  lastaccessed = "Aug 9, 2024",
}

@online{playCanvasWebsite,
  title = {PlayCanvas},
  author = {PlayCanvas},
  month = {July},
  year = {2024},
  url = {https://playcanvas.com/},
  lastaccessed = "July 28, 2024",
}

@online{playCanvasWebGPUSupport,
  title = {Initial WebGPU support lands in PlayCanvas Engine 1.62},
  author = {Valigursky, Martin},
  month = {March},
  year = {2023},
  url = {https://blog.playcanvas.com/initial-webgpu-support-lands-in-playcanvas-engine-1-62/},
  lastaccessed = "May 30, 2024",
}

@online{aFrameWebsite,
  title = {A-Frame},
  author = {A-Frame},
  month = {July},
  year = {2024},
  url = {https://aframe.io/},
  lastaccessed = "July 28, 2024",
}

@online{unityWebGLCompatibility,
  title = {Unity - Web browser compatibility},
  author = {Unity},
  month = {April},
  year = {2024},
  url = {https://docs.unity3d.com/2023.2/Documentation/Manual/webgl-browsercompatibility.html},
  lastaccessed = "July 28, 2024",
}

@online{UnityWebGPUSupport,
  title = {Web runtime updates are here: Take your browser to the next level},
  author = {Craven, Ben and Buscemi, Matthew and Bowker, Anthony},
  month = {November},
  year = {2023},
  url = {https://blog.unity.com/engine-platform/web-runtime-updates-enhance-browser-experience},
  lastaccessed = "May 30, 2024",
}

@online{WebGPUConformanceTestSuite,
  title = {WebGPU Conformance Test Suite},
  author = {{W3C group for GPU web standards}},
  month = {May},
  year = {2024},
  url = {https://github.com/gpuweb/cts},
  lastaccessed = "May 30, 2024",
}

@online{WebGPUCompatibilityModeProposal,
  title = {WebGPU Compatibility Mode},
  author = {White, Stephen},
  month = {October},
  year = {2023},
  url = {https://github.com/gpuweb/gpuweb/blob/bda661a/proposals/compatibility-mode.md},
  lastaccessed = "August 5, 2024",
}

@online{openPbrViewer,
  title = {OpenPBR-viewer},
  author = {Portsmouth, Jamie},
  month = {June},
  year = {2024},
  url = {https://github.com/portsmouth/OpenPBR-viewer},
  lastaccessed = "July 16, 2024",
}

@online{threeMeshBvh,
  title = {three-mesh-bvh},
  author = {Johnson, Garrett},
  month = {July},
  year = {2024},
  url = {https://github.com/gkjohnson/three-mesh-bvh},
  lastaccessed = "July 13, 2024",
}

@online{webgpuUtilsLib,
  title = {webgpu-utils},
  author = {Tavares, Gregg},
  month = {July},
  year = {2024},
  url = {https://github.com/greggman/webgpu-utils},
  lastaccessed = "July 26, 2024",
}

@online{pathTracerWallace,
  title = {WebGL Path Tracing},
  author = {Wallace, Evan},
  month = {August},
  year = {2011},
  url = {https://experiments.withgoogle.com/webgl-path-tracing},
  lastaccessed = "May 30, 2024",
}

@online{academicWebGLPathTracer,
  title = {Porting a CUDA Path Tracer to WebGL},
  author = {Jaškauskas, Andrius},
  month = {February},
  year = {2020},
  url = {https://github.com/driule/webgl-path-tracer},
  lastaccessed = "Aug 15, 2024",
}

@article{academicWebGLPathTracer2,
  title={Real-time path tracing of small scenes using WebGL},
  author={Nilsson, Martin and Ottedag, Alma},
  year={2018}
}

@online{ThreeJsPathTracerJohnson,
  title = {three-gpu-pathtracer},
  author = {Johnson, Garrett},
  month = {May},
  year = {2024},
  url = {https://github.com/gkjohnson/three-gpu-pathtracer},
  lastaccessed = "May 30, 2024",
}

@online{ThreeJsPathTracerLoftis,
  title = {THREE.js-PathTracing-Renderer},
  author = {Loftis, Erich},
  month = {May},
  year = {2024},
  url = {https://github.com/erichlof/THREE.js-PathTracing-Renderer},
  lastaccessed = "May 30, 2024",
}

@online{PathTracerDassault,
  title = {dspbr-pt},
  author = {Sdorra, Bastian and Häußler, Tobias},
  month = {July},
  year = {2022},
  url = {https://github.com/DassaultSystemes-Technology/dspbr-pt},
  lastaccessed = "May 30, 2024",
}

@online{gpuJS,
  title = {GPU.js},
  author = {{GPU.js}},
  month = {November},
  year = {2022},
  url = {https://github.com/gpujs/gpu.js},
  lastaccessed = "Aug 30, 2024",
}

@online{tensorflowJs,
  title = {A WebGL accelerated JavaScript library for training and deploying ML models},
  author = {{TensorFlow}},
  month = {August},
  year = {2024},
  url = {https://github.com/tensorflow/tfjs},
  lastaccessed = "Aug 30, 2024",
}

@online{vulkanRayTracing,
  title = {Vulkan SDK, Tools and Drivers are Ray Tracing Ready},
  author = {{Khronos Group}},
  month = {December},
  year = {2020},
  url = {https://www.khronos.org/news/press/vulkan-sdk-tools-and-drivers-are-ray-tracing-ready},
  lastaccessed = "Jul 25, 2024",
}

@online{webGPURayTracing,
  title = {Ray Tracing extension},
  author = {{W3C group for GPU web standards}},
  month = {January},
  year = {2020},
  url = {https://github.com/gpuweb/gpuweb/issues/535},
  lastaccessed = "Jul 25, 2024",
}

@online{webGPUSpirVRelation,
  title = {Define what bijective to SPIR-V means},
  author = {{W3C group for GPU web standards}},
  month = {February},
  year = {2020},
  url = {https://github.com/gpuweb/gpuweb/issues/582},
  lastaccessed = "Aug 5, 2024",
}

@online{webGPURayTracingFork,
  title = {Hardware Ray tracing extension for Chromium WebGPU},
  author = {Maier, Felix},
  month = {September},
  year = {2020},
  url = {https://github.com/maierfelix/dawn-ray-tracing},
  lastaccessed = "Jul 25, 2024",
}

@online{webGpuProfilingWithPix,
  title = {Profiling WebGPU with PIX},
  author = {Jones, Brandon},
  month = {January},
  year = {2024},
  url = {https://toji.dev/webgpu-profiling/pix},
  lastaccessed = "Aug 6, 2024",
}

@online{webGpuDevToolsDuncan,
  title = {Inspection debugger for WebGPU},
  author = {Duncan, Brendan},
  month = {August},
  year = {2024},
  url = {https://github.com/brendan-duncan/webgpu_inspector},
  lastaccessed = "Aug 6, 2024",
}

@online{webGpuDevToolsTakahiro,
  title = {webgpu-devtools},
  author = {Aoyagi, Takahiro},
  month = {May},
  year = {2023},
  url = {https://github.com/takahirox/webgpu-devtools},
  lastaccessed = "Aug 6, 2024",
}

@online{eaoProductReference,
  title = {Emergency stop switch, Series 45},
  author = {{EAO}},
  month = {August},
  year = {2024},
  url = {https://eao.com/product/45-2C36.1920.000~45-2300.1000.000~45-311.1X10~45-312.1X10/emergency_stop_switch/en/nothalt-taste-baureihe-45-40-mm-1-oe-1-s-ip66-ip67-ip69k-schraubanschluss},
  lastaccessed = "August 22, 2024",
}
