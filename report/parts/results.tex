%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% coding: utf-8
%%% End:
% !TEX TS-program = pdflatexmk
% !TEX encoding = UTF-8 Unicode
% !TEX root = ../main.tex

As discussed in the introduction and theory chapters, the goal of this work is to implement a web-based path tracer. The path tracer is designed to be used for product visualization based on CAD data, leveraging the \gls{OpenPBR} standard.

The concrete result of this work consists of multiple parts. The report serves as the primary documentation of the work, but does not contain all details. The library and code documentation are published under the MIT license on GitHub with an accompanying website. See \url{https://www.github.com/StuckiSimon/strahl} for details on this. The library is published on the \fgls{npm}{package manager for JavaScript} registry as \texttt{strahl}. In addition, a dedicated short-paper has been published for WEB3D '24: The 29th International ACM Conference on 3D Web Technology \cite{ownShortPaper}. The short-paper includes the main insights and results of this work.

This section focuses on the implementation details of the path tracer. It also highlights the reasoning behind design decisions and provides insights into the performance of the renderer.

This section contains references to the implementation of the path tracer. References are formatted in a consistent manner and can be searched for in the code. All relevant places are marked in code using the same reference. For example \coderef{ABC} refers to the code with the same comment.

\section{Scene Description}

In order to be easy to integrate for developers familiar with existing web-based rendering engines, the renderer utilizes many of the scene description constructs provided by \gls{Three.js}. This includes the representation of geometry using \texttt{BufferGeometry}, camera using \texttt{PerspectiveCamera}, and arbitrary camera controls such as \texttt{OrbitControls}.

This also enables to use a variety of loaders for different file formats such as \gls{OBJ} or \gls{glTF}. The path tracer uses the \gls{glTF} loader provided by \gls{Three.js}.

\section{Implementation}

The goal of the implementation is to be compatible with a large variety of devices and make the setup for consumers simple. Therefore, it is implemented and tested mainly in Chrome, which uses \gls{Dawn} as the underlying implementation of WebGPU. Most notably, this means that dedicated features from other implementations such as \gls{wgpu} cannot be used. Neither can experimental extensions be leveraged.

\subsection{Ray Tracing}

\subsubsection{OpenPBR}

The \gls{OpenPBR} standard is based on an \gls{uber shader} approach. This differs from node-based approaches such as \gls{MaterialX} in that it uses a fixed set of inputs which can be configured. This approach offers a good balance between flexibility and performance.

The surface shading method is based on \gls{OpenPBR} reference implementation in \gls{MaterialX} as well as the reference viewer by Portsmouth \cite{openPbrViewer}.

\subsubsection{RGB, Spectral}
\subsubsection{Memory Management}

In order to address memory alignment, as described in \autoref{ch:memoryAlignmentTheory}, the path tracer uses \texttt{webgpu-utils} \cite{webgpuUtilsLib}. The library enables a straightforward way to map data to buffers and align them correctly. See \coderef{MEMORY-VIEW} for creation of definition and \coderef{BUFFER-MAPPING} for mapping of data to buffers.

\todo{Memory Management (GPU+CPU)}

\subsection{View Projection}

For many applications, especially photorealistic rendering, perspective projection is used. Based on the assessed use cases, the path tracer uses perspective projection only. See \coderef{VIEWPROJECTION} for implementation.

\subsection{Random Number Generator}

The path tracer uses PCG-RXS-M-XS variant as described by Oâ€™Neill \cite{o2014pcg} in combination with Xorshift as described by Marsaglia \cite{marsaglia2003xorshift}. See \coderef{RNG} for implementation.

In order to set up the Monte Carlo method, the \gls{RNG} needs to be employed in a suitable manner. As it is a pseudorandom generator, it necessitates a seed to start the generation. If the seed is identical for all pixels, the results of a single sample will frequently share similar patterns in adjacent surfaces as shown in \autoref{fig:rngBadSeed}. The result for independent seeds differs in a stark manner as shown in \autoref{fig:rngGoodSeed}.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{resources/single-sample-bad-seed.png}
        \caption{identical seed for all pixels}
        \label{fig:rngBadSeed}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{resources/single-sample-good-seed.png}
        \caption{independent seed for every pixel}
        \label{fig:rngGoodSeed}
    \end{subfigure}
    \caption{Both images consist of only one sample.}
    \label{fig:rngSeed}
\end{figure}

When increasing the sample count, the differences in the setup remain visible. Adjacent surfaces show similar patterns as shown in \autoref{fig:rngNoiseArtifactsHighlightsBadNoisy}, which resemble image compression artifacts encountered in aggressively compressed \fGlspl{JPEG}{\e{Joint Photographic Experts Group}, common method for lossy image compression}. In contrast, the renderings with independent seeds show stark differences in adjacent pixels akin to noise as shown in \autoref{fig:rngNoiseArtifactsHighlightsGoodNoisy}. As shown in \autoref{fig:rngNoiseArtifactsHighlightsBadAnti} compared to \autoref{fig:rngNoiseArtifactsHighlightsGoodAnti}, the anti-aliasing is less noticeable when using independent seeds.

\begin{figure}[H]
    \centering
    \hspace*{2cm}
    \begin{subfigure}[t]{0.3\textwidth}
        \includegraphics[width=\textwidth]{resources/bad-seed-noisy.png}
        \caption{Renderings which resemble lossy image compression artifacts.}
        \label{fig:rngNoiseArtifactsHighlightsBadNoisy}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.3\textwidth}
        \includegraphics[width=\textwidth]{resources/good-seed-noisy.png}
        \caption{Noisy renderings with stark differences in adjacent pixels.}
        \label{fig:rngNoiseArtifactsHighlightsGoodNoisy}
    \end{subfigure}
    \hspace*{2cm}
    \vfill
    \vspace*{0.5cm}
    \hspace*{2cm}
    \begin{subfigure}[t]{0.3\textwidth}
        \includegraphics[width=\textwidth]{resources/bad-seed-anti-aliasing.png}
        \caption{On the right side, anti-aliasing is rather noticeable.}
        \label{fig:rngNoiseArtifactsHighlightsBadAnti}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.3\textwidth}
        \includegraphics[width=\textwidth]{resources/good-seed-anti-aliasing.png}
        \caption{On the right side, anti-aliasing is less noticeable.}
        \label{fig:rngNoiseArtifactsHighlightsGoodAnti}
    \end{subfigure}
    \hspace*{2cm}
    \caption{Magnified images of renderings with low sample count showing difference based on seed setup. Left column has identical seed for all pixels of a sample, but varying seeds for different samples. Right column has independent seeds for every pixel of a sample as well as across samples.}
    \label{fig:rngNoiseArtifactsHighlights}
\end{figure}

\subsection{Intersection Testing}

For \gls{BVH} construction, well-established solutions for the web are available. The path tracer uses \texttt{three-mesh-bvh} \cite{threeMeshBvh}. This method builds the \gls{BVH} on the \gls{CPU}, the code for transfering the \gls{BVH} to the \gls{GPU} is in \coderef{BVH-TRANSFER}, intersection tests are implemented in \gls{WGSL}, see \coderef{BVH-TESTS}.

\subsection{Anti-Aliasing}

The implementation of the strategy indicated in \ref{sec:anti-aliasing} is implemented in \coderef{ALIASING}.


\subsection{WebGPU}
\subsection{Integration}
\section{Use Case Scenarios}
\section{Performance}