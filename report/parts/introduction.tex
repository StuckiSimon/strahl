%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% coding: utf-8
%%% End:
% !TEX TS-program = pdflatexmk
% !TEX encoding = UTF-8 Unicode
% !TEX root = ../main.tex

This section provides an overview of applications of a real-time ray tracer and prior work conducted in this field, highlighting the base procedure and the novel aspects of this work. The goal is to demonstrate the potential and applicability of the developed solution. Details on the involved concepts and technologies will be discussed in \autoref{ch:theory}, but may already be referenced during the introduction.

Rasterization is a rendering technique that projects 3D scene geometry onto a 2D plane. Historically, the technique has been widely adopted in real-time rendering due to its efficiency. However, rasterization has limitations in achieving photorealism. One of the main limitations is the lack of support for global illumination. These phenomena can be observed in objects like mirrors or metallic surfaces. Effects such as refraction and reflection require additional techniques.

Various methods have been developed to address these limitations, but these approaches induce complexity, may need to be computed at the assembly level, and can be computationally expensive. An alternative rendering technique resembles reality more closely and inherently alleviates these limitations: ray tracing.

Ray tracing is a powerful technique for rendering photorealistic scenes including global illumination. Historically, ray tracing has been mainly used in offline rendering due to its computational complexity. However, advancements in hardware have enabled real-time ray tracing in a variety of domains. In addition, the development of a new web \fGls{API}{\e{Application Programming Interface}} for leveraging the power of \fGlspl{GPU}{\e{Graphics Processing Unit}, specialized processor for parallel computation}, WebGPU, has opened up new possibilities for real-time ray tracing in the browser.

\section{Use Cases}

The web is a versatile platform which can be used for a variety of applications. Most consumer devices have access to a web browser, which makes it an ideal platform for reaching a broad audience. Compared to native applications, web applications have the advantage of being platform-independent and do not require installation. This facilitates the distribution of applications and reduces the barrier of entry for users.

E-commerce represents a key use case for product renderings and frequently rely on taking pictures of the product. Similar to traditional physical catalogues, this approach struggles with highly configurable products due to the amount of images required to cover all possible configurations. Computer graphics addresses this challenge through product configurators for virtual assembly and visualization. They alleviate the need for physical processes, such as photography, and are scalable to a large number of configurations. This can be implemented by creating 3D models of the components and assembling them in a virtual environment. As the number of components grows, these components need to be kept in sync with the marketing models used for end user visualization.

In order to circumenvent this issue, leveraging existing production \gls{CAD} models, prevalent in mechanical engineering and product design, for end-user applications offers a significant advantage. These models contain geometric and material information, which eliminates the need for redundant 3D models for marketing purposes. One such example is EAO, which manufactures highly customizable industrial pushbuttons and operator panels. Due to the nature of the product, the number of possible assemblies grows almost exponentially with the number of components.

To illustrate the use case more universally, consider a product which is assembled of $n$ component types. Each component type ($i$) has $o_i$ different options. This gives the total amount of possible configurations ($t$) as shown in \autoref{eq:assemblyConfigurations}.

\begin{equation}
  t = \prod_{i=1}^n o_i
  \label{eq:assemblyConfigurations}
\end{equation}

Essentially, for a product consisting of $n$ component types and each component type having the same amount of options ($o$), the equation can be simplified to $t = o^n$. This demonstrates the exponential growth of possible assemblies.

Therefore, a web-based configurator leveraging computer graphics is well suited to address such use cases.

\section{Process}

In order to leverage production \gls{CAD} models, the models need to be pre-processed as visualized in Figure~\ref{fig:cad-preprocessing}. 

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\columnwidth]{resources/cad-pipeline-preprocessing.png}
  \caption{A two-step pre-processing stage is employed for offline as well as real-time rendering pipelines.}
  \label{fig:cad-preprocessing}
\end{figure}

The pre-processing step must define a rule set for the assembly. This rule set provides information on what kind of components can be added to the assembly and where they can be attached to. This can be done by providing meta information files containing the information. Alternatively, this can also be represented geometrically within the model by using identifiable shapes to attach components to. \fGls{STEP}{\e{Standard for the Exchange of Product model data}, a standard formalized in ISO 10303 for product manufacturing information.} files are a common format for exchanging \gls{CAD} data and can be used for this purpose, but as will be discussed in \autoref{ch:specializedFormats}, other formats are more suitable for rendering and address inheret limitations of \gls{STEP} files.

This includes triangulation of the meshes, which is a common requirement for rendering engines. Frequently, the triangulated meshes are fine-grained and consist of a large number of triangles. This can lead to performance issues when rendering the scene. One option to handle this is to simplify the meshes by decimating triangles. Procedures for this purpose are well established and include algorithms for generating level of detail (\gls{LOD}) artifacts \cite{luebke2003level}.

Another important consideration are intellectual property rights when using \gls{CAD} models from production processes. The models may contain proprietary information which should not be disclosed to the end user. As described by Stjepandić et al. \cite{ipr}, steps may include data filtering. Such filtering can occur by removing meta information such as constraints or by removing occluded parts of the model, essentially limiting the model to the hull of the assembly. As a positive side-effect, this can also reduce the complexity of the model, which can be beneficial for rendering performance.
While numerous \gls{CAD} formats include material information, it is often unsuitable for rendering. To address this, a material mapping can be defined, translating \gls{CAD} materials to a suitable representation for the rendering pipeline.

After the preparation process, a rendering architecture paradigm can be employed to provide the virtually assembled products.

\section{Paradigms}

In order to render the assemblies based on the pre-processed information, three main paradigms can be employed for web-based applications: offline rendering, client side real-time rendering, and remote real-time rendering. These paradigms differ significantly and the technology stack varies significantly between them. Therefore, the choice of paradigm is crucial for the implementation of the application.

\subsection*{Offline Rendering}

Offline rendering, requires pre-rendering all product configurations. This is theoretically possible for a finite number of configurations, but computationally expensive. 

An offline rendering pipeline generates static images of the assembly, which are then displayed in the browser. This means that all possible assemblies need to be rendered and stored upfront. As the number of components increases, the number of possible combinations grows exponentially, which can lead to large amounts of storage and processing power being required, as shown in Figure~\ref{fig:cad-offline}.

\begin{figure}[H]
  \includegraphics[width=\columnwidth]{resources/cad-pipeline-offline.png}
  \caption{In an offline rendering setup, the number of images grows exponentially. The number of images increases further when offering 360° viewing.}
  \label{fig:cad-offline}
\end{figure}

\subsection*{Client Side Real-time Rendering}

An alternative to offline rendering is real-time rendering. These approaches render the assemblies only as requested by the end user.

For real-time rendering, client-side rendering is a frequently  used option. Most frequently, rasterization approaches are used for web-based renderings. However, due to the limitations in global illumination effects, the need for a real-time, client-side ray tracing solution for the web becomes apparent when considering the use case.

This is the main benefit of using a real-time rendering pipeline, as illustrated in Figure~\ref{fig:cad-online}. The rendering is done in the browser, which means that the server only needs to provide the geometry and material information in an exchange format such as glTF. This approach is more flexible and can be used for a larger number of configurations. The amount of data to be stored and processed offline grows linearly with the number of components, independent of the number of possible configurations.

\begin{figure}[H]
  \includegraphics[width=\columnwidth]{resources/cad-pipeline-online.png}
  \caption{A real-time rendering pipeline solely relies on having an adequate model for each component of the assembly. It does not require pre-rendering every possible configuration.}
  \label{fig:cad-online}
\end{figure}

\subsection*{Remote Real-time Rendering}

For real-time rendering, an alternative paradigm is remote rendering \cite{remoteRendering}, which employs a server to render the scene and stream the visualization to the browser. The main drawbacks of this approach are network latency, reliance on network stability, as well as operational cost for the server infrastructure, which frequently requires dedicated \glspl{GPU} for rendering.

\begin{figure}[H]
  \includegraphics[width=\columnwidth]{resources/cad-pipeline-remote.png}
  \caption{A remote rendering pipeline relies on a server to consistently stream the data in real-time to the client.}
  \label{fig:cad-remote}
\end{figure}

\subsection*{Assessment}

Each of the paradigms has its own advantages, the following table highlights the strengths and weaknesses of each approach and provides a comparison in terms of use cases.

\todo{This table slightly overflows.}
\begin{table}[H]\centering
  \ra{1.3}
  \begin{tabular}{@{}lccc@{}}\toprule
   & \bfseries Offline Rendering & \bfseries Client Side & \bfseries Remote \\
  Pre-Processing Cost & high & low & low \\
  Hosting Cost & low & low & high \\
  Storage & high & low & low \\
  Performance & network-dependent & device-dependent & network-dependent \\
  Interactivity & low & high & high \\
  Network dependency & low & low & high \\
  Possible Scene Complexity & high & device-dependent & high \\
  \bottomrule
  \end{tabular}
  \caption{High-level comparison between different rendering architecture paradigms.}
\end{table}

\subsubsection{Pre-Processing Cost}

This measure how much computation is required to prepare the data for rendering. Generally, lower is better. Offline rendering needs to pre-render all assemblies, essentially doing exhaustive rendering. Client side rendering and remote rendering need similar pre-processing.

\subsubsection{Hosting Cost}

The cost involved in hosting the application. Generally, lower is better. Offline rendering does not require application servers and mainly relies on storage for the generated images. Similarly, client side rendering needs storage for the models and textures. Remote rendering requires a rendering server, which can be costly.

\subsubsection{Storage}

The amount of storage required for the application. Generally, lower is better. Offline rendering requires storage for all rendered images. Client side rendering requires storage for the models and textures, as does remote rendering.

\subsubsection{Performance}

The main bottleneck in terms of rendering performance for the end user. Offline rendering generally sends static images, a highly optimized process. Rendering such images is generally faster than real-time rendering, which is heavily dependent on the device. Remote rendering is also dependent on the network connection.

\subsubsection{Interactivity}

The level of interactivity the user can expect. Generally, higher gives more flexibility. Offline rendering means all possible views need to be pre-rendered. Extending views requires additional pre-rendering, which optimally is done using a delta change detection to prevent re-rendering unchanged views. Client side rendering and remote rendering enable real-time interaction of the user without constraints. They also enable experimentation with different view configurations.

\subsubsection{Network Dependency}

The reliance on a stable network connection. Generally, lower is better. Offline rendering needs to load the images, which is rather efficient. Client side rendering requires an initial connection to download the models but is independent afterwards. Remote rendering consistently requires a stable connection to stream the rendered images.

\subsubsection{Possible Scene Complexity}

The complexity of the scene that can be rendered. Generally, higher gives more flexibility. Offline rendering can handle complex scenes given dedicated hardware. Client side rendering is dependent on the device, generally the weakest supported device defines the possible scene complexity. Remote rendering can handle complex scenes.

\section{Prior Work}

Work has been conducted in related fields, this includes research into applicability of WebGPU as well as writing web based path tracers using WebGL. However, to the best of my knowledge, no open-source path tracing library using WebGPU has been developed.

\subsection*{WebGPU}

Different other applications of WebGPU have been investigated in the past years. One such example is Dynamical.JS, a framework to visualize graphs \cite{dotson2022dynamicaljs}. Another example is RenderCore, a research-oriented rendering engine \cite{Bohak_Kovalskyi_Linev_Mrak_Tadel_Strban_Tadel_Yagil_2024}, or demonstrations on how to use WebGPU for client-side data aggregation \cite{kimmersdorfer2023webgpu}.

Investigation into the performance of WebGPU have been conducted and show that WebGPU can be faster than WebGL \cite{webGPUWebGis, fransson2023performance, CHICKERUR2024919}.
 

\subsection*{Web Path Tracers}

There are a variety of path tracers available for the web. Most of them are based on WebGL, a web standard which will be highlighted in the following sections.

The first experiments of using WebGL for path tracing were implemented as early as 2010. One such example is the demo by Evan Wallace showcasing a Cornell Box with basic primitive shapes such as spheres and planes \cite{pathTracerWallace}.

Since then, a variety of open-source implementations for the web have been created.

\subsection*{Three.js-based Ray Tracers}

Some of the most widely known path tracers are based on Three.js. Including:

\begin{itemize}
    \item {\texttt{three-gpu-pathtracer}} \cite{ThreeJsPathTracerJohnson}.
    \item{\texttt{Three.js PathTracer}} \cite{ThreeJsPathTracerLoftis}.
    \item {\texttt{dspbr-pt}} \cite{PathTracerDassault}.
  \end{itemize}
