%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% coding: utf-8
%%% End:
% !TEX TS-program = pdflatexmk
% !TEX encoding = UTF-8 Unicode
% !TEX root = ../main.tex

This section provides an overview of concrete applications and high-level procedures of a real-time 3D renderers. Furthermore, it introduces prior work conducted in this field, highlighting the novel aspects of this work. The goal is to demonstrate the potential and applicability of the developed solution. Details on the involved concepts and technologies will be discussed in \autoref{ch:theory}, but may already be referenced briefly during the introduction.

\section{Use Cases}

The web is a versatile platform which can be used for a variety of applications. Most consumer devices have access to a web browser, which makes it an ideal platform for reaching a broad audience. Compared to native applications, web applications have the advantage of being platform-independent and do not require installation. This facilitates the distribution of applications and reduces the barrier of entry for users.

E-commerce represents a key use case for product renderings. Commonly, these applications rely on taking pictures of the product. Similar to traditional physical catalogues, this approach struggles with highly configurable products due to the amount of images required to cover all possible configurations. Computer graphics addresses this challenge through product configurators for virtual assembly and visualization. They alleviate the need for physical processes, such as photography, and are scalable to a large number of configurations. This can be implemented by creating 3D models of the components and assembling them in a virtual environment.

As the number of components grows and the product evolves, these production models need to be kept in sync with the marketing models used for end user visualization. In order to circumenvent this issue, leveraging existing production \gls{CAD} models, prevalent in mechanical engineering and product design, for end-user applications offers a significant advantage. These models contain geometric and material information, which eliminates the need for redundant 3D models for marketing purposes. One such example is EAO, which manufactures highly customizable industrial pushbuttons and operator panels. Due to the nature of the product, the number of possible assemblies grows almost exponentially with the number of components. The presented work uses EAO production models to demonstrate the feasibility and challenges of real-time rendering of highly configurable products.

To illustrate the use case more universally, consider a product which is assembled of $n$ component types. Each component type ($i$) has $o_i$ different options. This gives the total amount of possible configurations ($t$) as shown in \autoref{eq:assemblyConfigurations}.

\begin{equation}
  t = \prod_{i=1}^n o_i
  \label{eq:assemblyConfigurations}
\end{equation}

Essentially, for a product consisting of $n$ component types and each component type having the same amount of options ($o$), the equation can be simplified to $t = o^n$. This demonstrates the exponential growth of possible assemblies.

One example at EAO is a specific product family within the so-called series 45. It has 14 component types ($n$) and each component type has approximately 10 different options ($o$). This results in $10^{14}$ possible configurations ($t$) based on 140 different components. In addition, EAO has many more product series as well as product families with varying numbers of components and options. This constitutes the main use case considered for this thesis.

Therefore, a web-based configurator leveraging computer graphics for virtual assembly is well suited to address such use cases where almost exponential growth in possible configurations is present.

\section{CAD Data Processing}

In order to leverage production \gls{CAD} models, the models need to be pre-processed as visualized in Figure~\ref{fig:cad-preprocessing}. 

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\columnwidth]{resources/cad-pipeline-preprocessing.png}
  \caption{A two-step pre-processing stage is employed for offline as well as real-time rendering pipelines.}
  \label{fig:cad-preprocessing}
\end{figure}

The pre-processing step must define a rule set for the assembly. This rule set provides information on what kind of components can be added to the assembly and where they can be attached to. This can be done by providing meta information files containing the information. Alternatively, this can also be represented geometrically within the model by using identifiable shapes to attach components to. \fGls{STEP}{\e{Standard for the Exchange of Product model data}, a standard formalized in ISO 10303 for product manufacturing information.} files are a common format for exchanging \gls{CAD} data and can be used for this purpose, but as will be discussed in \autoref{ch:specializedFormats}, other formats are more suitable for rendering and address inheret limitations of \gls{STEP} files.

Pre-processing includes triangulation of the meshes, which is a common requirement for rendering engines. Frequently, the triangulated meshes are fine-grained and consist of a large number of triangles. This can lead to performance issues when rendering the scene. One option to handle this is to simplify the meshes by decimating triangles. Procedures for this purpose are well established and include algorithms for generating level of detail (\gls{LOD}) artifacts \cite{luebke2003level}.

Another important consideration are intellectual property rights when using \gls{CAD} models from production processes. The models may contain proprietary information which should not be disclosed to the end user. As described by Stjepandić et al. \cite{ipr}, steps to circumvent this issue may include data filtering. Filtering can occur by removing meta information such as constraints or by removing occluded parts of the model, essentially limiting the model to the hull of the assembly. As a positive side-effect, this can also reduce the complexity of the model, which can be beneficial for rendering performance.
While numerous \gls{CAD} formats include material information, it is often unsuitable for rendering. To address this, a material mapping can be defined, translating \gls{CAD} materials to a suitable representation for the rendering pipeline.

After the preparation process, a rendering architecture paradigm can be employed to enable users to virtually assemble the product.

\section{Rendering Architecture Paradigms}

In order to render the assemblies based on the pre-processed information, three main paradigms can be employed for web-based applications: offline rendering, client side real-time rendering, and remote real-time rendering. These paradigms differ significantly and the technology stack varies significantly between them. Therefore, the choice of paradigm is crucial for the implementation of the application.

\subsection*{Offline Rendering}

Offline rendering, requires pre-rendering all product configurations. This is theoretically possible for a finite number of configurations, but computationally expensive. 

An offline rendering pipeline generates static images of the assembly, which are then displayed in the browser. This means that all possible assemblies need to be rendered and stored upfront. As the number of components increases, the number of possible combinations grows exponentially, which can lead to large amounts of storage and processing power being required, as shown in Figure~\ref{fig:cad-offline}.

\begin{figure}[H]
  \includegraphics[width=\columnwidth]{resources/cad-pipeline-offline.png}
  \caption{In an offline rendering setup, the number of images grows exponentially. The number of images increases further when offering 360° viewing.}
  \label{fig:cad-offline}
\end{figure}

Interactivity is limited by requiring all desired viewing angles to be defined upfront. 360° viewing experience using a single degree of freedom can be provided by rendering images in regular intervals. 100 images would be needed to get an image every 3.6°. These images can then be loaded in the browser as the user drags. However, if more degrees of freedom, different lighting situations, and zoom levels need to be supported, a similar growth in rendered images can be observed as for the assemblies.

In order to address latency, pre-loading images can be used. This may entail loading additional images in the background to enable a smooth user experience. However, this leads to increased bandwith usage.

\subsection*{Client Side Real-time Rendering}

An alternative to offline rendering is real-time rendering. For real-time rendering, client-side rendering is a frequently  used option. These approaches render the assemblies only as requested by the end user. This is the main benefit of using a real-time rendering pipeline, as illustrated in Figure~\ref{fig:cad-online}. The rendering is done in the browser, which means that the server only needs to provide the geometry and material information in a 3D exchange format such as \fgls{glTF}{\e{Graphics Library Transmission Format, common 3D exchange format optimized for transmission and real-time rendering.}}. This approach is more flexible and can be used for a larger number of configurations. The amount of data to be stored and processed offline grows linearly with the number of components, independent of the number of possible configurations.

\begin{figure}[H]
  \includegraphics[width=\columnwidth]{resources/cad-pipeline-online.png}
  \caption{A real-time rendering pipeline solely relies on having an adequate model for each component of the assembly. It does not require pre-rendering every possible configuration.}
  \label{fig:cad-online}
\end{figure}

This approach limits the technology which can be used for rendering. The rendering is done in the browser, which means that it is dependent on the browser engine as well as the specific device hardware. This is also a limitation in terms of the complexity of the scene that can be rendered.

\subsection*{Remote Real-time Rendering}

For real-time rendering, an alternative paradigm is remote rendering \cite{remoteRendering}, which employs a server to render the scene and stream the visualization to the browser. The main drawbacks of this approach are network latency, reliance on network stability, as well as operational cost for the server infrastructure, which frequently requires dedicated \fGlspl{GPU}{\e{Graphics Processing Unit}, specialized processor for parallel computation} for rendering.

\begin{figure}[H]
  \includegraphics[width=\columnwidth]{resources/cad-pipeline-remote.png}
  \caption{A remote rendering pipeline relies on a server to consistently stream the data in real-time to the client.}
  \label{fig:cad-remote}
\end{figure}

To fulfill thresholds frequently used for real-time rendering, the network latency should be below 20 ms. Recent studies on this have shown that this is still a challenge, even when considering the fastest networks available at a given location. Many locations do not have access to any cloud data centers with a latency below 20 ms. \cite{cloudLatency}

\subsection*{Comparison}

To evaluate the different paradigms, a set of critera where the paradigms differ are defined. These criteria are used to demonstrate the advantages and disadvantages of each paradigm.

\subsubsection{Pre-Processing Cost}

Measure how much computation effort is required to prepare the data for rendering. Generally, lower is better. Offline rendering needs to pre-render all assemblies, essentially doing exhaustive rendering. Client side rendering and remote rendering only need basic pre-processing.

\subsubsection{Hosting Cost}

The infrastructure cost involved in hosting the application during operations. Generally, lower is better. Offline rendering does not require application servers and mainly relies on storage for the generated images. Similarly, client side rendering needs storage for the models. These two paradigms may employ classic \fglspl{CDN}{\e{Content Delivery Network}, distributed group of servers for caching content near end users.}. Remote rendering requires a rendering server, which can be costly and may induce additional complexity. In addition, bandwidth costs need to be considered.

\subsubsection{Storage}

The amount of data storage required for the application. Generally, lower is better. Offline rendering requires storage for all rendered images, possibly in multiple resolutions to support different types of devices. Client side rendering only requires storage for the models, as does remote rendering.

\subsubsection{Main Performance Dependency}

The main bottleneck in terms of rendering performance for the end user. Offline rendering generally sends static images, a highly optimized process. Rendering such images is generally faster than real-time rendering, which is heavily dependent on the device hardware. Remote rendering is also dependent on the network connection.

\subsubsection{Interactivity}

The level of interactivity the user can expect. Generally, higher gives more flexibility. Offline rendering means all possible views need to be pre-rendered. Extending views requires additional pre-rendering, which optimally is done using a delta change detection to prevent re-rendering unchanged views. Client side rendering and remote rendering enable real-time interaction of the user without constraints. They also enable easier experimentation with different view configurations and possibly open up the possibility for using content provided by the end user in the rendering process. Such content could be lighting condition, background, or even additional objects.

\subsubsection{Network Dependency}

The reliance on a stable network connection. Generally, lower is better. Offline rendering needs to load the images, which is rather efficient. Client side rendering requires an initial connection to download the models but is independent afterwards. Remote rendering consistently requires a stable connection to stream the rendered images.

\subsubsection{Maximum Scene Complexity Dependency}

The main bottleneck in terms of the complexity of the scene that can be rendered. Generally, using a server gives more flexibility as the provider has full control over the hardware capabilities. Offline rendering can handle complex scenes given such dedicated hardware. Client side rendering is dependent on the device, generally the weakest supported device defines the possible scene complexity. Remote rendering can handle complex scenes, similar to offline rendering.

\subsection*{Assessment}
\label{ch:paradigmAssessment}

Each of the paradigms has its own advantages, \autoref{tab:paradigmComparison} highlights the strengths and weaknesses of each approach and provides a comparison of the criteria.

\begin{table}[H]
  \centering
  \ra{1.3}
  \begin{tabular}{@{}p{5cm}p{2.5cm}p{2.5cm}p{2.5cm}@{}}
  \toprule
  Rendering Paradigm & \textbf{Offline} & \multicolumn{2}{c}{\textbf{Real-time}} \\
   &  & \textbf{Client Side} & \textbf{Remote} \\
  Pre-Processing Cost & High & Low & Low \\
  Hosting Cost & Low & Low & High \\
  Storage & High & Low & Low \\
  Main Performance Dependency & network & device & network \\
  Interactivity & Low & High & High \\
  Network dependency & Low & Low & High \\
  Max Complexity Dependency & server & device & server \\
  \bottomrule
  \end{tabular}
  \caption{High-level comparison between different rendering architecture paradigms.}
  \label{tab:paradigmComparison}
\end{table}

Offline rendering is suitable for applications where pre-generating all images is feasible and limited interactivity is acceptable. Real-time rendering, either client side or remote, is a suitable choice for aplications where the number of possible configurations is high and interactivity is important. The choice between client side and remote rendering depends on the network infrastructure and the complexity of the scene.
Generally, client side rendering setups can be extended to support remote rendering as well as offline rendering, whereas offline rendering setups as well as remote rendering setups are possibly not capable of client side rendering due to technical constraints imposed by the available technology. Based on this assessment, this work focuses on client side rendering, with the potential to extend to other paradigms in the future.

\section{Prior Work}

This section highlights related work for web-based client side real-time rendering. A rough overview of the different approaches is given, but more detailed information on the concepts, the technologies, their strengths and weaknesses, and the the benefits ray tracing provides will be discussed in \autoref{ch:computerGraphics}.

Rasterization is a rendering technique that projects 3D scene geometry onto a 2D plane. Historically, the technique has been widely adopted in real-time rendering due to its efficiency. However, rasterization has limitations in achieving photorealism. One of the main limitations is the lack of support for global illumination. These phenomena can be observed in objects like mirrors or metallic surfaces. Effects such as refraction and reflection require additional techniques.

Various methods have been developed to address these limitations, but these approaches induce complexity, may need to be computed at the assembly level, and can be computationally expensive. An alternative rendering technique resembles reality more closely and inherently alleviates these limitations: ray tracing.

Ray tracing is a powerful technique for rendering photorealistic scenes including global illumination. Historically, ray tracing has been mainly used in offline rendering due to its computational complexity. However, advancements in hardware have enabled real-time ray tracing in a variety of domains.

\subsection*{Web-based Real-Time Renderers}

A number of web-based real-time rasterizers exist. The main options include:

\begin{itemize}
  \item {\gls{Three.js}} \cite{threeJSWebsite} — popular web rendering engine.
  \item {\texttt{Babylon.js}} \cite{babylonJSWebsite} — popular web rendering engine.
  \item {\texttt{PlayCanvas}} \cite{playCanvasWebsite} — game engine for the web.
  \item {\texttt{A-Frame}} \cite{aFrameWebsite} — web framework for building virtual reality experiences.
\end{itemize}

In addition, \gls{Unity}, a common game engine for desktop and mobile applications also supports \fgls{WebGL}{\e{Web Graphics Library}, since 2011 the de-facto standard API for rendering 3D graphics on the web} \cite{unityWebGLCompatibility}.

These engines focus on rasterization techniques and are widely used for web-based applications. The focus of these engines lies on real-time rendering performance as used in games, advertising campaigns, virtual reality (VR), augmented reality (AR), medical imaging, scientific visualization, and educational applications. However, they lack support for ray tracing techniques. 

\subsection*{Web Path Tracers}

Path tracing is a specific ray tracing technique. There are a variety of path tracers available for the web. Most of them are based on \gls{WebGL}. The first experiments of using \gls{WebGL} for path tracing were implemented as early as 2010. One such example is the Google experiment demonstrating a Cornell Box \cite{goral1984modeling} with basic primitive shapes such as spheres and planes \cite{pathTracerWallace}.

Since then, a variety of open-source implementations for the web have been created. Some of the most widely known path tracers are based on \gls{Three.js}.

\subsubsection{three-gpu-pathtracer}

One of the most widely known path tracers for the web is the \texttt{three-gpu-pathtracer} by Johnson \cite{ThreeJsPathTracerJohnson}. This path tracer is implemented as a \gls{Three.js} plugin and uses \gls{WebGL} for rendering.  It is bundled as a library and can be used to render scenes in the browser.

\subsubsection{Three.js PathTracer}

Another path tracer based on \gls{Three.js} is the \texttt{Three.js PathTracer} by Loftis \cite{ThreeJsPathTracerLoftis}. This path tracer is also implemented as a \gls{Three.js} plugin and uses \gls{WebGL} for rendering. It does not provide a library, but can serve as a basis for further development.

\subsubsection{dspbr-pt}

The \texttt{dspbr-pt} by Dassault Systèmes \cite{PathTracerDassault} is a path tracer implemented in \gls{WebGL}. It is based on the \texttt{three-gpu-pathtracer} and provides additional features such as support for \gls{OBJ} files. It implements the Enterprise PBR Shading Model. However, the implementation does not provide a library and also hasn't been updated in the past years.

\subsection*{WebGPU}

WebGPU is a new web \fGls{API}{\e{Application Programming Interface}} for leveraging the power of \glspl{GPU}. Various applications of WebGPU have been investigated in recent years. Examples include Dynamical.JS, a framework for visualizing graphs \cite{dotson2022dynamicaljs}; RenderCore, a research-oriented rendering engine \cite{Bohak_Kovalskyi_Linev_Mrak_Tadel_Strban_Tadel_Yagil_2024}; and demonstrations of how to use WebGPU for client-side data aggregation \cite{kimmersdorfer2023webgpu}.

Research on the performance comparison between existing 3D engines and WebGPU engines has been conducted as part of the development of FusionRender, which concluded that measurable performance gains can be achieved by using WebGPU, but only when effectively leveraging its novel design principles \cite{fusionRenderWebGPU}. Similar findings have emerged from other independent studies, demonstrating that WebGPU can be faster than \gls{WebGL} \cite{webGPUWebGis, fransson2023performance, CHICKERUR2024919}.

\subsection*{Conclusion}

Work has been conducted in related fields, this includes research into applicability of WebGPU as well as writing web based path tracers using \gls{WebGL}. However, the research suggests that no open-source path tracing library using WebGPU has been developed. In light of these findings, WebGPU presents a transformative opportunity. It is particularly well-suited for the development of a new real-time path tracing library for the web which provides an alternative approach to existing rasterization-based rendering engines.
