%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% coding: utf-8
%%% End:
% !TEX TS-program = pdflatexmk
% !TEX encoding = UTF-8 Unicode
% !TEX root = ../main.tex

This section discusses the results in more detail. The experience gained by implementing a project using WebGPU is discussed. In addition, a more detailed discussion of the results is provided.

The ray tracer focuses on the given use case and is therefore not a general-purpose rendering engine. For example, it does not offer a physics engine, support for animations, or other features that are common in general-purpose rendering engines such as \gls{Three.js}, \gls{Babylon.js} or similar.

Generally, the ray tracing technique will be slower than rasterization-based approaches and is therefore not a silver bullet for all use cases.

\section{Findings}
\subsection{WebGPU Stability and Adoption}

Due to the current state of support for WebGPU in Safari and Mozilla Firefox, the production readiness of WebGPU is still limited. Safari has announced plans to support WebGPU and has launched a preview version \cite{SafariWebGPUSupport}. Firefox also has plans to support WebGPU \cite{FirefoxWebGPUSupport}. Thanks to the extensive conformance test suite \cite{WebGPUConformanceTestSuite}, it is more likely that the different implementations will be compatible with each other.

The main browser which supports WebGPU to date is Chrome. WebGPU has shipped to general use on desktops in May of 2023 \cite{ChromeWebGPUSupport}. Since January 2024, WebGPU is also supported on modern Android devices \cite{ChromeAndroidWebGPUSupport}.

This means that it's straightforward to use WebGPU on most modern devices with the notable exception of Apple iOS and iPadOS devices.

\subsubsection{Missing Features}

To date, WebGPU does not support some features that are common in modern rendering APIs.

\paragraph{Ray Tracing}

\glspl{API} such as Vulkan support hardware-accelerated ray tracing \cite{vulkanRayTracing}. This entails helpers for building common acceleration structures, such as \gls{BVH}, as well as ray querying functions to determine intersections. WebGPU does not yet support these features, but there are discussions ongoing to add extensions \cite{webGPURayTracing} as well as a demonstration implemented in a Dawn fork \cite{webGPURayTracingFork}.


\section{Future Work}

\subsection{Rendering Effects}

The focus on the defined use case means that certain rendering effects are not implemented. These include:

\begin{itemize}
    \item{Caustics}.
    \item{Volumetric Effects} - Volumetric effects include fog, smoke and dust.
    \item {Depth of Field} - Depth of field is the effect of objects at different distances from the camera being in focus or out of focus.
    \item {Motion Blur} - Motion blur is the effect of objects moving quickly appearing blurred.
\end{itemize}

\subsection{Full OpenPBR support}

The current implementation only supports the features of the OpenPBR surface shading model that are required for the given use case. The full OpenPBR specification includes additional features that could be implemented to improve the realism of the rendered images. These include:

\begin{itemize}
    \item{Subsurface Scattering} - Subsurface scattering is the effect of light entering a surface and being scattered beneath the surface before exiting at a different point. This effect is common in materials such as skin, wax, or marble.
\end{itemize}

\todo{list all features}

\subsection{Low-Level Performance Optimizations}

The current implementation is not optimized for performance. Therefore, it is likely that optimizations of the \gls{WGSL} code could improve the performance of the renderer.

\subsection{Web Worker Support}

Web Workers are a web technology that allows running scripts off the main thread. This can be used to offload \gls{CPU}-heavy tasks to a separate thread to prevent blocking the main thread which is responsible for rendering the user interface.

\subsection{BVH Construction}

The current implementation builds the \gls{BVH} on the \gls{CPU} and transfers it to the \gls{GPU}. Corresponding research \cite{lauterbach2009GPUbvh} suggests that moving parts of the construction to the \gls{GPU} directly could improve performance. This would reduce the amount of data that needs to be transferred between the \gls{CPU} and the \gls{GPU}. The new \gls{GPGPU} capabilities of WebGPU further enable this approach.

\subsection{TypeScript Support for Memory Management}

While \texttt{webgpu-utils} \cite{webgpuUtilsLib} is useful for memory management, it does not provide TypeScript support for the generated definitions based on the underlying \gls{WGSL} code. Type safety could reduce the likelihood of errors in the code. As an alternative, runtime checks could be implemented to ensure that the data is correctly mapped to all fields of the underlying structure.

\subsection{Offline and Remote Rendering}

As highlighted in \autoref{ch:paradigmAssessment}, it is possible to extend a real-time client side renderer to be used in offline and remote rendering scenarios. In order to implement offline rendering, one could opt to use a headless browser such as Puppeteer, a \fgls{Node.js}{JavaScript runtime, frequently used for executing JavaScript outside of the browser} library which provides a high-level \gls{API} to control browsers. An alternative is to use \gls{wgpu}, but this would necessitate a rewrite of the renderer. Possibly, the rewritten renderer could also be used in the web context by using \fgls{WebAssembly}{Portable Binary-code format for executable programs available in modern browser engines}.

For remote rendering, the renderer could be extended to render images on demand and encode them as video streams.

\subsection{WebGPU Compatibility Mode}

There is a proposal under active development which aims to extend the reach of WebGPU by providing a slighly restricted subset of WebGPU \cite{WebGPUCompatibilityModeProposal}. Considering the suggested limits of the compatibility mode, it could be possible to deploy the renderer onto a wider range of devices. However, it is important to consider that path tracing is a computationally expensive task and might not be suitable for all devices. Therefore, increasing the reach might not be beneficial in all cases.

\subsection{Qualitative Assessment}

The provided results highlight the quantitative performance of the renderer. However, due to the nature of a renderer, qualitative assessment based on visual inspection is also used to determine the quality of the rendered images. This could be extended to include more advanced metrics such as peak signal to noise ratio (PSNR), structural similarity (SSIM) \cite{ssim}, or learned perceptual image patch similarity (LPIPS) \cite{lpips}.

Such a comparison could be based on reference scenes such as the Cornell Box \cite{goral1984modeling} or the Sponza Atrium \cite{dabrovic2002sponza}. To assess the differences, a number of tests could be conducted:

\begin{itemize}
    \item{Offline Renderer Comparison} - Comparison to other offline renderers such as Cycles \cite{cycles}, Mitsuba \cite{Jakob2020DrJit} or \gls{pbrt} \cite{Pharr_Physically_Based_Rendering_2023}.
    \item{Rasterization Renderer Comparison} - Comparison to rasterization-based web renderers such as \gls{Three.js} or \gls{Babylon.js}.
    \item{Web-based Path Tracer Comparison} - Comparison to other web-based path tracers such as \texttt{three-gpu-pathtracer} \cite{ThreeJsPathTracerJohnson}, \texttt{Three.js PathTracer} \cite{ThreeJsPathTracerLoftis}, or \texttt{dspbr-pt} \cite{PathTracerDassault}.
\end{itemize}


\subsection{ReSTIR}
\subsection{SHaRC}

https://intro-to-restir.cwyman.org/